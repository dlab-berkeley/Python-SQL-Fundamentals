{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe48a7aa",
   "metadata": {},
   "source": [
    "# SQL for Data Analysis  \n",
    "### Introductory Workshop\n",
    "*D‚ÄëLab, UC¬†Berkeley*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173bfe0c-a0aa-44a6-8afa-5ed8e5d23c40",
   "metadata": {},
   "source": [
    "### Welcome & Environment Check \n",
    "\n",
    "Estimated time: 8 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69798bf",
   "metadata": {},
   "source": [
    "## Table of Contents  \n",
    "1. [Why SQL?](#why-sql)\n",
    "3. [Relational Databases](#relational)    \n",
    "4. [Importing CSV ‚Üí SQLite](#sqlite)  \n",
    "5. [SQLite Data Types & NULLs](#types)  \n",
    "6. [SELECT & Derived Columns](#select)  \n",
    "7. [Filtering Rows with WHERE](#where)  \n",
    "8. [Aggregates & GROUP¬†BY](#groupby)  \n",
    "9. [Sorting & Paging Results](#orderby)   \n",
    "10. [Key Points & Next Steps](#keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c357b9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"> \n",
    "<b>Learning Goals</b><br><br>\n",
    "By the end of this workshop you will be able to:\n",
    "<ul>\n",
    "<li>Understand why one would use SQL and why and how it is complementary to Pandas</li>\n",
    "<li>Write basic queries with <code>SELECT</code>, create aliases, and build derived columns.</li>\n",
    "<li>Filter rows using <code>WHERE</code>, sort and paginate result sets with <code>ORDER¬†BY</code>, <code>LIMIT</code>, <code>OFFSET</code>.</li>\n",
    "<li>Summarise data with aggregates &nbsp;(<code>COUNT</code>, <code>SUM</code>, <code>AVG</code>, <code>MIN</code>, <code>MAX</code>)&nbsp; and <code>GROUP¬†BY</code>.</li>\n",
    "<li>Filter groups with <code>HAVING</code> and understand why it is different from <code>WHERE</code></li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18846946",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Prerequisites</b><br><br>\n",
    "Before starting this workshop, you should:\n",
    "<ul>\n",
    "<li>Have basic familiarity with data analysis concepts</li>\n",
    "<li>Have Python and Jupyter Notebook installed (optional, but helpful for following along)</li>\n",
    "<li>Download the workshop materials (we'll provide these)</li>\n",
    "<li>Not strictly necessary, but it would be very useful to have a notion of how to do operations on Pandas (or any other similar library/package/software) to better contextualize the material.</li>\n",
    "</ul>\n",
    "\n",
    "No prior SQL experience is required!\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>Setup Note</b><br><br>\n",
    "If you want to follow along with the exercises: <br>\n",
    "1. Make sure you have the required Python packages installed:<br>\n",
    "   - pandas<br>\n",
    "   - sqlite3<br>\n",
    "   - sqlalchemy<br>\n",
    "2. Download the example database file we'll be using\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcee7c91-54b9-494e-8fab-4042f404677a",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce8be261-d760-4db0-b353-865dc1e52418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ The sqlite3 library is imported and available.\n",
      "‚úÖ The database file is available and in the appropriate folder\n"
     ]
    }
   ],
   "source": [
    "# Importing packages that we will need\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd         \n",
    "import os, pathlib, sys\n",
    "\n",
    "# The first thing we need to do is connect to our SQLite database, which is the file that stores the information we will be using.\n",
    "# If there is no pre-existing database with this name, it automatically creates one.\n",
    "# Every SQL query will be executed through this `conn` object - which can be thought as a channel to the SQLite file.\n",
    "conn = sqlite3.connect('../Data/customers.sqlite')\n",
    "engine = create_engine('sqlite:///customers.sqlite')\n",
    "\n",
    "# Load the customers table into a DataFrame for displ\n",
    "\n",
    "\n",
    "# Troubleshooting: Please run the following cells to check whether sqlite is imported and the database file is in its appropriate location!\n",
    "\n",
    "try:\n",
    "    import sqlite3                        \n",
    "    print(\"‚úÖ The sqlite3 library is imported and available.\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå sqlite3 library not found.\")\n",
    "\n",
    "# 2Ô∏è‚É£ Check that the workshop DB file exists\n",
    "from pathlib import Path\n",
    "print(\"‚úÖ The database file is available and in the appropriate folder\" if Path(\"../Data/customers.sqlite\").exists()\n",
    "      else \"‚ùå ../Data/customers.sqlite is missing‚Äîdownload the data bundle and place it there.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7d556f-308a-42d0-8f4d-3e34434c0180",
   "metadata": {},
   "source": [
    "### Icons Used in This Notebook\n",
    "üîî **Question**: A quick question to help you understand what's going on.<br>\n",
    "ü•ä **Challenge**: Interactive exercise. We'll work through these in the workshop!<br>\n",
    "üí° **Tip**: How to do something a bit more efficiently or effectively.<br>\n",
    "‚ö†Ô∏è **Warning:** Heads-up about tricky stuff or common mistakes.<br>\n",
    "üìù **Poll:** A Zoom poll to help you learn!<br>\n",
    "üé¨ **Demo**: Showing off something more advanced ‚Äì so you know what Python can be used for!<br>\n",
    "üôã Hands-Up: Quick pulse-check or mini-quiz. Respond by choosing the option that matches how you feel/what you think."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a03e0eb",
   "metadata": {},
   "source": [
    "<a id='why-sql'></a>\n",
    "## 1‚ÄØ¬∑‚ÄØWhy SQL? \n",
    "\n",
    "Estimated time: 15 minutes\n",
    "\n",
    "A very common question when people learn about the existence of SQL is: Why bother learning it? Can't I just use pandas and pandas dataframes?\n",
    "\n",
    "### Learning Objective\n",
    "Understand when and why to use SQL instead of pandas, and how these tools complement each other in data analysis workflows.\n",
    "\n",
    "üìù **Poll 1:** What is the usual size of databases you use? How large do you think databases can get?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06897baf",
   "metadata": {},
   "source": [
    "### Bookcase¬†vs¬†Desk Analogy  \n",
    "Think of your computer‚Äôs RAM as the desk where you spread papers you‚Äôre actively working on, and the hard‚Äëdrive as the bookcase that stores all your books.\n",
    "\n",
    "Working at your desk is fast, but at the same time it doesn't hold nearly as much material as a bookshelf. So if you are working with very large datasets, you are at risk of overloading your desk with material. \n",
    "\n",
    "* **Pandas** is excellent for analysis of *smaller* data that fits comfortably on the desk.  \n",
    "* **SQL** is the tool we use to selectively bring only the information we need from the bookcases to the desk.\n",
    "\n",
    "üôã **Hands-Up:** Did the analogy make sense? A. Yes‚ÄÉB. Still fuzzy\n",
    "\n",
    " **Example:** A 20‚ÄØGB transaction table can be grouped and aggregated with a single SQL statement, whereas pandas would first need 20‚ÄØGB of memory just to read the file.\n",
    "\n",
    "### Rough size sweet-spots on a single machine\n",
    "\n",
    "- **Pandas (all in RAM)** ‚Äì ideal up to **‚âà 5 million rows** (around **500 MB** of CSV). Beyond that, Python overhead (‚âà 5‚Äì10√ó the raw file size) quickly exhausts memory.  \n",
    "- **SQLite (single-file engine)** ‚Äì stays responsive with **tens or even hundreds of millions of rows** (roughly **10‚Äì500 GB**). Because it streams pages from disk, RAM is rarely the bottleneck. File-system ceiling: ‚âà 280 TB.  \n",
    "- **PostgreSQL (server engine)** ‚Äì comfortably handles **100 GB to several terabyte tables** on industrial hardware; technical cap is **32 TB per table**, but overall database size is **unlimited**\n",
    "\n",
    "\n",
    "### Complements, not Substitutes \n",
    "In practice we often:\n",
    "\n",
    "1. Use SQL to slice/aggregate huge tables, producing a manageable result set  \n",
    "2. Pull that into pandas for plotting or modelling\n",
    "\n",
    "**üí°Tip:** When working with large datasets, try to do as much filtering and aggregation as possible in SQL before pulling data into pandas. This can dramatically improve performance!\n",
    "\n",
    "üîî **Question:**  Have you ever dealt with a problem in which SQL was necessary? If not, can you think of one real life application that might require it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419f7c30",
   "metadata": {},
   "source": [
    "<a id='relational'></a>\n",
    "## 2‚ÄØ¬∑‚ÄØRelational Databases \n",
    "\n",
    "Estimated time: 12 minutes\n",
    "\n",
    "### Learning Objective\n",
    "Grasp the fundamental concepts of relational databases, including tables, keys, and relationships between data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b4020f",
   "metadata": {},
   "source": [
    "## What is a Relational Database?\n",
    "\n",
    "<div class=\"alert alert-primary\">\n",
    "<b>üîë Key Concept: Relational Databases</b><br><br>\n",
    "A relational database organizes data into tables (sometimes called relations), which consist of rows and columns:\n",
    "\n",
    "- **Tables**: Collections of related data (e.g., Customers, Orders)\n",
    "- **Columns**: Specific attributes (e.g., CustomerID, FirstName)\n",
    "- **Rows**: Individual records in the table\n",
    "- **Primary Keys**: Unique identifiers for each row\n",
    "- **Foreign Keys**: References to primary keys in other tables that create relationships\n",
    "\n",
    "![Database sample of Customers, Orders and OrderDetails tables, highlighting how relational data splits across tables.](../Images/relational-databases.svg)\n",
    "\n",
    "Let's take a look at these example:\n",
    "- Combined, these two tables form a database - a collection of data organized in tables.\n",
    "- In this particular case, there are two tables, each one storing one type of information - either about Customers, or about Orders. But databases usually consist of many tables!\n",
    "- Each table consists of rows - identifying individual records of information - and columns, which provide a piece of information for a given field corresponding to each row.\n",
    "- Both of these tables have primary keys - columns that uniquely identify each row, i.e, each row has one, and no two rows share a primary key. Notice however the two tables do not have the same primary key!\n",
    "- Further, the Order table has a foreign key \"Customer ID\" - a column linking to the primary key of the Customers table. Each order can be associated to a single customer through this relationship. But that doesn't mean each customer has just one order!\n",
    "\n",
    "üìù **Poll 2:** Can you think of a table that would not have a Primary Key?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1a9e10-a518-48ee-9baa-0e42f5a2088f",
   "metadata": {},
   "source": [
    "<a id='sqlite'></a>\n",
    "## 3 ¬∑ Getting Started with SQLite \n",
    "\n",
    "Estimated Time: 10 minutes\n",
    "\n",
    "### Learning Objective\n",
    "Understand how to set up SQLite, import data from CSV files, and establish a database connection for querying data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b316844-fb7e-458a-84ea-31be758e93f8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## What is SQLite?\n",
    "\n",
    "SQLite is a lightweight relational database. It is easy to install, use, and even though it doesn't have as many advanced capabilities as PostgreSQL or MySQL, it is a great way to start learning SQL. \n",
    "\n",
    "SQL queries are very similar (if not identical) across these programs, so there is a lot of transfer of knowledge if you decide to move on to another one in the future.\n",
    "\n",
    "### When to Use Different Databases\n",
    "\n",
    "| What You're Doing | SQLite | MySQL/PostgreSQL |\n",
    "|-------------------|--------|------------------|\n",
    "| Getting Started | Great for learning SQL | More complex to set up |\n",
    "| Working Locally |  Just a file you can copy | Needs server installation |\n",
    "| Small-Medium Projects |  Up to ~1TB of data | Any size |\n",
    "| Data Science Projects |  Works great with Python | Needs more setup |\n",
    "| Team Projects | Limited sharing options | Better for collaboration |\n",
    "\n",
    "üí° **Real-World Examples**:\n",
    "- **SQLite**: Your Jupyter notebooks, research projects, personal data analysis\n",
    "- **MySQL/PostgreSQL**: Company databases, shared research data, production systems\n",
    "\n",
    "The key takeaway: SQLite is perfect for learning SQL and doing your own data analysis. When you need to share data with a team or work on very large datasets, you can easily switch to MySQL or PostgreSQL - the SQL commands will be almost exactly the same!\n",
    "\n",
    "\n",
    "üìù **Poll 3:** What's your primary reason for learning SQL today? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7560fa93-c30b-4f59-8ac8-d33a117bf070",
   "metadata": {},
   "source": [
    "### SQLite and Python\n",
    "\n",
    "In this workshop, we'll work with SQLite directly in a Jupyter notebook using the `sqlite3` Python library, which comes built into Python.\n",
    "\n",
    "We could create tables with `CREATE TABLE` statements, as well as add new data (INSERT), change existing data (UPDATE), and remove data (DELETE) directly on SQL, but in this workshop we will focus on querying data from a pre-existing database. I have added an example of how can this be done in an auxiliary file that I used to create the database for this workshop, if you would like to explore that later!\n",
    "\n",
    "\n",
    "üí°**Tip:** In this workshop we will be focusing on databases that contain a single table. In the next workshop, we will learn how to combine information from multiple tables. \n",
    "\n",
    "Let's upload our sql database as a dataframe in pandas:\n",
    "\n",
    "customers_df = pd.read_sql_query('SELECT * FROM customers', conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958ae643-8dd7-4618-a9cf-f2f6b212db02",
   "metadata": {},
   "source": [
    "ü•ä **Challenge**: Can you use pandas to take a look at what this dataset looks like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6975afe-2062-48b0-880a-ede98f40b3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>items_purchased</th>\n",
       "      <th>price_per_item</th>\n",
       "      <th>last_purchase</th>\n",
       "      <th>account_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Smith</td>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.28</td>\n",
       "      <td>None</td>\n",
       "      <td>945.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maria Garcia</td>\n",
       "      <td>London</td>\n",
       "      <td>GB</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-08-18</td>\n",
       "      <td>905.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Li Wei</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>JP</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.18</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>638.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emma Brown</td>\n",
       "      <td>Paris</td>\n",
       "      <td>FR</td>\n",
       "      <td>8.0</td>\n",
       "      <td>64.68</td>\n",
       "      <td>2024-01-28</td>\n",
       "      <td>929.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ahmed Hassan</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>AU</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.35</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>179.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name      city country  items_purchased  price_per_item  \\\n",
       "0    John Smith  New York      US              NaN           56.28   \n",
       "1  Maria Garcia    London      GB             15.0             NaN   \n",
       "2        Li Wei     Tokyo      JP             11.0           14.18   \n",
       "3    Emma Brown     Paris      FR              8.0           64.68   \n",
       "4  Ahmed Hassan    Sydney      AU              7.0           25.35   \n",
       "\n",
       "  last_purchase  account_balance  \n",
       "0          None           945.55  \n",
       "1    2024-08-18           905.34  \n",
       "2    2024-02-10           638.11  \n",
       "3    2024-01-28           929.69  \n",
       "4    2024-05-14           179.64  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SOLUTION:\n",
    "customers_df.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f897e82d",
   "metadata": {},
   "source": [
    "<a id='types'></a>\n",
    "## 4‚ÄØ¬∑‚ÄØSQLite Data Types & `NULL` \n",
    "\n",
    "Estimated time: 7 minutes\n",
    "\n",
    "### Learning Objective\n",
    "Understand SQLite's data types and how NULL values are handled in SQL databases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f538c404",
   "metadata": {},
   "source": [
    "SQLite has a flexible approach to data types. While columns are designed with a recommended data type (like TEXT or INTEGER), SQLite can actually store any type of data in any column.\n",
    "\n",
    "* **INTEGER** ‚Äì whole numbers \n",
    "* **REAL** ‚Äì floating‚Äëpoint  \n",
    "* **TEXT** ‚Äì strings    \n",
    "* **NULL** ‚Äì missing / undefined  \n",
    "\n",
    "Unlike PostgreSQL/MySQL, SQLite does NOT have a date format, but it does have dedicated functions that interpret strings as dates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6fe208",
   "metadata": {},
   "source": [
    "<a id='select'></a>\n",
    "## 5‚ÄØ¬∑‚ÄØSELECT & Derived Columns \n",
    "\n",
    "Estimated time: 18 minutes\n",
    "\n",
    "### Learning Objective\n",
    "Master the fundamental SQL SELECT statement, including column selection, aliasing, and creating derived columns using basic SQL functions.\n",
    "\n",
    "Real-World Application: Extract the relevant customer information for a marketing campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de336ab3-a620-4815-9435-ef9a1884a575",
   "metadata": {},
   "source": [
    "### The SELECT statement is the foundation of SQL queries. We'll learn it step by step:\n",
    "\n",
    "1. Basic SELECT - Retrieving data from tables\n",
    "2. Column Aliases - Giving friendly names to columns\n",
    "3. Derived Columns - Creating new columns from existing ones\n",
    "4. SQL Functions - Transforming data in useful ways\n",
    "\n",
    "üí° Tip: We'll build from simple queries to more complex ones, making sure each concept is clear before moving on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b1d2c2-434b-4bd5-be25-ae31e59278e4",
   "metadata": {},
   "source": [
    "At its most basic version, a query looks like this:\n",
    "\n",
    "```sql\n",
    "SELECT column1, column2, ‚Ä¶\n",
    "FROM   table;\n",
    "```\n",
    "\n",
    "- One of the most confusing aspects of SQL, especially in the beginning, is understading the order in which SQL reads the instructions of a query - which unfortunately is not the order in which the commands are written.\n",
    "- Here it is better to think that the first command is \"FROM\" - which tells us where to draw the information from\n",
    "- After that, we can select only the columns we will need by listing them after the SELECT statement.\n",
    "- Notice that:\n",
    "    - We don't need to put names of columns and tables between quotes\n",
    "    - We do need to separate different columns by commas - but not one at the end!\n",
    "\n",
    "üôã **Hands-Up:** Which clause executes *first* in SQL‚Äôs logical order? A. `SELECT`‚ÄÉB. `FROM`‚ÄÉC. `WHERE`\n",
    "\n",
    "üí° **Tip**: When selecting multiple columns, use line breaks after commas for better readability!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cb48082-f50e-4e31-b15d-beef77b47e45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic SELECT:\n",
      "\n",
      "                name         city country  items_purchased\n",
      "0         John Smith     New York      US              NaN\n",
      "1       Maria Garcia       London      GB             15.0\n",
      "2             Li Wei        Tokyo      JP             11.0\n",
      "3         Emma Brown        Paris      FR              8.0\n",
      "4       Ahmed Hassan       Sydney      AU              7.0\n",
      "5      Sarah Johnson       Berlin      DE             19.0\n",
      "6   Carlos Rodriguez       Mumbai      IN             11.0\n",
      "7      Anna Kowalski    S√£o Paulo      BR             11.0\n",
      "8       James Wilson      Toronto      CA              4.0\n",
      "9        Yuki Tanaka     Shanghai      CN              8.0\n",
      "10       Elena Popov       Madrid      ES              3.0\n",
      "11     Michel Dubois       Moscow      RU              2.0\n",
      "12      Sofia Santos        Dubai      AE             12.0\n",
      "13     Lars Andersen         None    None              6.0\n",
      "14       Aisha Patel  Mexico City      MX              2.0\n",
      "15    Diego Martinez    Amsterdam      NL              1.0\n",
      "16         Lucy Chen        Cairo      EG             12.0\n",
      "17       Ivan Petrov    Stockholm      SE             12.0\n",
      "18     Mary Williams         None    None             17.0\n",
      "19         Raj Kumar  Los Angeles      US             10.0\n",
      "20      Hans Schmidt         Rome      IT             16.0\n",
      "21    Isabella Silva    Hong Kong      HK             15.0\n",
      "22    Fatima Al-Said     Istanbul      TR              NaN\n",
      "23          Jun Park        Seoul      KR             19.0\n",
      "24      Anna Ivanova      Bangkok      TH             12.0\n"
     ]
    }
   ],
   "source": [
    "# Basic SELECT query\n",
    "query = \"\"\"\n",
    "SELECT name, city, country, items_purchased\n",
    "FROM customers\n",
    "\"\"\"\n",
    "result = pd.read_sql_query(query, conn)\n",
    "print(\"Basic SELECT:\\n\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78021ea7-f2b9-4f1b-909b-33fcd1a479d7",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Warning:** Common Mistake - Missing commas between columns\n",
    "```sql\n",
    "-- ‚ùå WRONG: Missing commas\n",
    "SELECT name city country\n",
    "FROM customers\n",
    "\n",
    "-- ‚úÖ CORRECT: Columns separated by commas\n",
    "SELECT name, city, country\n",
    "FROM customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813a20c8-208c-442b-a578-af51f14d7cd4",
   "metadata": {},
   "source": [
    "However, queries are extremely flexible and allow us to combine/summarize information in many ways.\n",
    "\n",
    "Let's take a look at some examples of more interesting queries\n",
    "\n",
    "### Step‚Äëby‚ÄëStep Examples\n",
    "\n",
    "1. **Select everything:**\n",
    "\n",
    "\n",
    "   If you want to keep all columns from a table, you can just use * instead of naming the columns.\n",
    "\n",
    "\n",
    "   ```sql\n",
    "   SELECT * \n",
    "   FROM customers;\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9626d61-2d8d-49cc-ba3f-8451edefc1fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * - All columns:\n",
      "\n",
      "                name         city country  items_purchased  price_per_item  \\\n",
      "0         John Smith     New York      US              NaN           56.28   \n",
      "1       Maria Garcia       London      GB             15.0             NaN   \n",
      "2             Li Wei        Tokyo      JP             11.0           14.18   \n",
      "3         Emma Brown        Paris      FR              8.0           64.68   \n",
      "4       Ahmed Hassan       Sydney      AU              7.0           25.35   \n",
      "5      Sarah Johnson       Berlin      DE             19.0           15.85   \n",
      "6   Carlos Rodriguez       Mumbai      IN             11.0           95.40   \n",
      "7      Anna Kowalski    S√£o Paulo      BR             11.0           96.91   \n",
      "8       James Wilson      Toronto      CA              4.0           82.76   \n",
      "9        Yuki Tanaka     Shanghai      CN              8.0           37.42   \n",
      "10       Elena Popov       Madrid      ES              3.0           18.79   \n",
      "11     Michel Dubois       Moscow      RU              2.0           71.58   \n",
      "12      Sofia Santos        Dubai      AE             12.0           49.61   \n",
      "13     Lars Andersen         None    None              6.0           20.98   \n",
      "14       Aisha Patel  Mexico City      MX              2.0           54.57   \n",
      "15    Diego Martinez    Amsterdam      NL              1.0           13.09   \n",
      "16         Lucy Chen        Cairo      EG             12.0           91.84   \n",
      "17       Ivan Petrov    Stockholm      SE             12.0           33.29   \n",
      "18     Mary Williams         None    None             17.0           69.63   \n",
      "19         Raj Kumar  Los Angeles      US             10.0           38.05   \n",
      "20      Hans Schmidt         Rome      IT             16.0             NaN   \n",
      "21    Isabella Silva    Hong Kong      HK             15.0           59.20   \n",
      "22    Fatima Al-Said     Istanbul      TR              NaN           26.64   \n",
      "23          Jun Park        Seoul      KR             19.0           97.26   \n",
      "24      Anna Ivanova      Bangkok      TH             12.0           79.76   \n",
      "\n",
      "   last_purchase  account_balance  \n",
      "0           None           945.55  \n",
      "1     2024-08-18           905.34  \n",
      "2     2024-02-10           638.11  \n",
      "3     2024-01-28           929.69  \n",
      "4     2024-05-14           179.64  \n",
      "5     2024-07-19              NaN  \n",
      "6     2024-11-23           140.70  \n",
      "7     2024-09-24           392.80  \n",
      "8     2024-02-02           449.81  \n",
      "9     2024-02-17           344.21  \n",
      "10    2024-03-02           845.86  \n",
      "11    2024-08-03           421.08  \n",
      "12    2024-10-19           352.84  \n",
      "13    2024-04-08           588.43  \n",
      "14    2024-06-20           226.83  \n",
      "15    2024-12-25           821.98  \n",
      "16    2024-08-01           167.10  \n",
      "17    2024-02-04           988.20  \n",
      "18    2024-08-14           795.02  \n",
      "19    2024-04-10              NaN  \n",
      "20          None           104.97  \n",
      "21    2024-09-13           833.92  \n",
      "22          None           736.17  \n",
      "23    2024-08-05           756.11  \n",
      "24    2024-09-11           794.14  \n"
     ]
    }
   ],
   "source": [
    "# Select all columns example\n",
    "select_all_query = \"\"\"\n",
    "SELECT * \n",
    "FROM customers\n",
    "\"\"\"\n",
    "result = pd.read_sql_query(select_all_query, conn)\n",
    "print(\"SELECT * - All columns:\\n\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca022924-82fa-4db6-9e2e-0f73c46f2644",
   "metadata": {},
   "source": [
    "üîî **Question:** When might using SELECT * be problematic in a real database?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ab7a4-3380-46ba-9e88-7684aff33430",
   "metadata": {},
   "source": [
    "### 5.2 Column Aliases\n",
    "\n",
    "    Sometimes tables have very complicated/uninformative/ambiguous names. We can rename the header of a column using an alias, which is a new name to columns in our result. This is useful when:\n",
    "    - Making technical names more readable\n",
    "    - Clarifying the meaning of computed columns\n",
    "    - Creating reports for non-technical users\n",
    "\n",
    "Syntax using AS (recommended for clarity):\n",
    "\n",
    "   ```sql\n",
    "   SELECT column AS new_name,\n",
    "   FROM   table;\n",
    "   ```\n",
    "\n",
    "Alternative syntax (implicit):\n",
    "\n",
    "   ```sql\n",
    "   SELECT column new_name,\n",
    "   FROM   table;\n",
    "   ```\n",
    "\n",
    "‚ö†Ô∏è **Warning:** If your new name contains spaces or is a special name, you must wrap it in quotes:\n",
    "\n",
    "   ```sql\n",
    "   SELECT column AS \"Full Name\",\n",
    "   FROM   table;\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3722d850-ce58-4134-9dce-1978c0687fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT with Aliases: \n",
      "\n",
      "       customer_name     location  quantity  unit_price\n",
      "0       Maria Garcia       London      15.0         NaN\n",
      "1             Li Wei        Tokyo      11.0       14.18\n",
      "2         Emma Brown        Paris       8.0       64.68\n",
      "3       Ahmed Hassan       Sydney       7.0       25.35\n",
      "4      Sarah Johnson       Berlin      19.0       15.85\n",
      "5   Carlos Rodriguez       Mumbai      11.0       95.40\n",
      "6      Anna Kowalski    S√£o Paulo      11.0       96.91\n",
      "7       James Wilson      Toronto       4.0       82.76\n",
      "8        Yuki Tanaka     Shanghai       8.0       37.42\n",
      "9        Elena Popov       Madrid       3.0       18.79\n",
      "10     Michel Dubois       Moscow       2.0       71.58\n",
      "11      Sofia Santos        Dubai      12.0       49.61\n",
      "12     Lars Andersen         None       6.0       20.98\n",
      "13       Aisha Patel  Mexico City       2.0       54.57\n",
      "14    Diego Martinez    Amsterdam       1.0       13.09\n",
      "15         Lucy Chen        Cairo      12.0       91.84\n",
      "16       Ivan Petrov    Stockholm      12.0       33.29\n",
      "17     Mary Williams         None      17.0       69.63\n",
      "18         Raj Kumar  Los Angeles      10.0       38.05\n",
      "19      Hans Schmidt         Rome      16.0         NaN\n",
      "20    Isabella Silva    Hong Kong      15.0       59.20\n",
      "21          Jun Park        Seoul      19.0       97.26\n",
      "22      Anna Ivanova      Bangkok      12.0       79.76\n"
     ]
    }
   ],
   "source": [
    "# Column aliases example\n",
    "alias_query = \"\"\"\n",
    "SELECT \n",
    "    name AS customer_name,\n",
    "    city AS location,\n",
    "    items_purchased AS quantity,\n",
    "    price_per_item AS unit_price\n",
    "FROM customers\n",
    "WHERE items_purchased IS NOT NULL\n",
    "\"\"\"\n",
    "result = pd.read_sql_query(alias_query, conn)\n",
    "print(\"SELECT with Aliases: \\n\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3408e250-286c-4d0c-8278-390f5815f3e2",
   "metadata": {},
   "source": [
    "### 5.3 Derived Columns\n",
    "\n",
    "Very commonly we might want to create what we call a \"Derived Column\" - which is a column that modifies/combines information from columns of the original table. \n",
    "\n",
    "The way that we do this is usually by using functions. The syntax is function(column_name). We treat them as if they were regular columns.\n",
    "\n",
    "Common Uses:\n",
    "- Perform calculations\n",
    "- Combine text\n",
    "- Transform data\n",
    "\n",
    "Basic syntax:\n",
    "```sql\n",
    "SELECT \n",
    "    original_column,\n",
    "    expression AS new_column\n",
    "FROM table;\n",
    "```\n",
    "\n",
    "Common uses:\n",
    "1. Arithmetic: `price * quantity AS total`\n",
    "2. Text concatenation: `first_name || ' ' || last_name AS full_name`\n",
    "3. Simple calculations: `price * 1.2 AS price_with_tax`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee9318d-95a3-4840-be95-394629ea41fd",
   "metadata": {},
   "source": [
    "![Workflow diagram showing SQL string concatenation that creates a ‚Äúsummary‚Äù column from name, price and quantity fields.](../Images/derivedcolumn.svg)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea3c085d-8760-429e-b3d0-57645af0b094",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT Example with Derived Columns: \n",
      "\n",
      "          lower_name   upper_city  double_items\n",
      "0         john smith     NEW YORK           NaN\n",
      "1       maria garcia       LONDON          30.0\n",
      "2             li wei        TOKYO          22.0\n",
      "3         emma brown        PARIS          16.0\n",
      "4       ahmed hassan       SYDNEY          14.0\n",
      "5      sarah johnson       BERLIN          38.0\n",
      "6   carlos rodriguez       MUMBAI          22.0\n",
      "7      anna kowalski    S√£O PAULO          22.0\n",
      "8       james wilson      TORONTO           8.0\n",
      "9        yuki tanaka     SHANGHAI          16.0\n",
      "10       elena popov       MADRID           6.0\n",
      "11     michel dubois       MOSCOW           4.0\n",
      "12      sofia santos        DUBAI          24.0\n",
      "13     lars andersen         None          12.0\n",
      "14       aisha patel  MEXICO CITY           4.0\n",
      "15    diego martinez    AMSTERDAM           2.0\n",
      "16         lucy chen        CAIRO          24.0\n",
      "17       ivan petrov    STOCKHOLM          24.0\n",
      "18     mary williams         None          34.0\n",
      "19         raj kumar  LOS ANGELES          20.0\n",
      "20      hans schmidt         ROME          32.0\n",
      "21    isabella silva    HONG KONG          30.0\n",
      "22    fatima al-said     ISTANBUL           NaN\n",
      "23          jun park        SEOUL          38.0\n",
      "24      anna ivanova      BANGKOK          24.0\n"
     ]
    }
   ],
   "source": [
    "# Derived columns with string functions\n",
    "select_derived_query = \"\"\"\n",
    "SELECT \n",
    "    LOWER(name) AS lower_name,\n",
    "    UPPER(city) AS upper_city,\n",
    "    items_purchased * 2 AS double_items\n",
    "FROM customers\n",
    "\"\"\"\n",
    "print(\"SELECT Example with Derived Columns: \\n\")\n",
    "print(pd.read_sql_query(select_derived_query, conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca7862-2846-4241-b347-0f9b3b1fcd8e",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è Warning: Common Mistake - Using double quotes for string values\n",
    "\n",
    "```sql\n",
    "--‚ùå WRONG: Double quotes for string values\n",
    "WHERE country = \"USA\"\n",
    "\n",
    "-- ‚úÖ CORRECT: Single quotes for strings\n",
    "WHERE country = 'USA'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e4b702c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT Example with Combined Columns: \n",
      "\n",
      "                name    full_location  total_spent\n",
      "0         John Smith     New York, US          NaN\n",
      "1       Maria Garcia       London, GB          NaN\n",
      "2             Li Wei        Tokyo, JP       155.98\n",
      "3         Emma Brown        Paris, FR       517.44\n",
      "4       Ahmed Hassan       Sydney, AU       177.45\n",
      "5      Sarah Johnson       Berlin, DE       301.15\n",
      "6   Carlos Rodriguez       Mumbai, IN      1049.40\n",
      "7      Anna Kowalski    S√£o Paulo, BR      1066.01\n",
      "8       James Wilson      Toronto, CA       331.04\n",
      "9        Yuki Tanaka     Shanghai, CN       299.36\n",
      "10       Elena Popov       Madrid, ES        56.37\n",
      "11     Michel Dubois       Moscow, RU       143.16\n",
      "12      Sofia Santos        Dubai, AE       595.32\n",
      "13     Lars Andersen             None       125.88\n",
      "14       Aisha Patel  Mexico City, MX       109.14\n",
      "15    Diego Martinez    Amsterdam, NL        13.09\n",
      "16         Lucy Chen        Cairo, EG      1102.08\n",
      "17       Ivan Petrov    Stockholm, SE       399.48\n",
      "18     Mary Williams             None      1183.71\n",
      "19         Raj Kumar  Los Angeles, US       380.50\n",
      "20      Hans Schmidt         Rome, IT          NaN\n",
      "21    Isabella Silva    Hong Kong, HK       888.00\n",
      "22    Fatima Al-Said     Istanbul, TR          NaN\n",
      "23          Jun Park        Seoul, KR      1847.94\n",
      "24      Anna Ivanova      Bangkok, TH       957.12\n"
     ]
    }
   ],
   "source": [
    "# Combining columns and calculations\n",
    "select_combined_query = \"\"\"\n",
    "SELECT \n",
    "    name,\n",
    "    city || ', ' || country AS full_location,\n",
    "    items_purchased * price_per_item AS total_spent\n",
    "FROM customers\n",
    "\"\"\"\n",
    "print(\"SELECT Example with Combined Columns: \\n\")\n",
    "print(pd.read_sql_query(select_combined_query, conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4e57b8-710e-4c2d-bb7a-b88a98a4f993",
   "metadata": {},
   "source": [
    "üîî **Question:** Why are we getting NaN's in the last column? How can we avoid this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a76a50-e6e9-47ba-9d27-615b72724c2f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>üí° Best Practices</b><br><br>\n",
    "1. Always explicitly list the columns you need <br>\n",
    "2. Use meaningful aliases for clarity<br>\n",
    "3. Format queries with proper indentation<br>\n",
    "4. Add comments for complex queries<br>\n",
    "5. Test queries with a subset of data first\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb407d",
   "metadata": {},
   "source": [
    "### Commonly used Functions\n",
    "\n",
    "We won't be able to cover all of them, but for future reference, here is a quick list of commonly used functions:\n",
    "\n",
    "#### Text functions\n",
    "\n",
    "| Function | Description | Example |\n",
    "|----------|-------------|---------|\n",
    "| `SUBSTR(text, start, len)` | Substring (1‚Äëbased index) | `SUBSTR('Market',1,3)` ‚Üí `Mar` |\n",
    "| `INSTR(text, pattern)` | Position (0 if not found) | `INSTR('abcdef','cd')` ‚Üí `3` |\n",
    "| `LOWER(text)` / `UPPER(text)` | Case conversion | `LOWER('SQL')` ‚Üí `sql` |\n",
    "| `REPLACE(text, old, new)` | Global substitution | `REPLACE('foo','o','0')` |\n",
    "| `TRIM(text)` | Strip leading/trailing spaces | |\n",
    "| `str1 \\|\\| ' merging character ' \\|\\| str2 \\|\\|` | Concatenates strings\n",
    "\n",
    "#### Date / time Functions\n",
    "\n",
    "| Function | What it does | Example |\n",
    "|----------|--------------|---------|\n",
    "| `DATE('now')` | Current date (UTC) | `DATE('now')` ‚Üí `'2025‚Äë05‚Äë07'` |\n",
    "| `DATETIME('now','localtime')` | Current local datetime | `DATETIME('now','localtime')` ‚Üí `'2025‚Äë05‚Äë07¬†13:25:00'` |\n",
    "| `STRFTIME(fmt, ts)` | Format timestamp ‚Üí text | `STRFTIME('%Y‚Äë%m', OrderDate)` ‚Üí `'1997‚Äë07'` |\n",
    "| `JULIANDAY(ts)` | Days since noon¬†4714‚ÄØBC | `JULIANDAY('2025‚Äë05‚Äë07')` ‚Üí `2460457.5` |\n",
    "\n",
    "\n",
    "#### Integer and Float Functions\n",
    "\n",
    "| Expression | Result |\n",
    "|------------|--------|\n",
    "| `column1 + column2` | Add two numbers |\n",
    "| `ROUND(total * 0.15, 2)` | Round to 2‚ÄØdecimal places |\n",
    "| `COALESCE(price, 0)` | Replace NULL with 0 |\n",
    "\n",
    "üí°**Tip:** Need a float? Multiply an `INTEGER` by **`1.0`**.\n",
    "\n",
    "Now that we know the basics of querying, we can start dealing with more complex query commands - such as filtering, grouping, aggregate functions, sorting and paginating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f442956",
   "metadata": {},
   "source": [
    "<a id='where'></a>\n",
    "## 6‚ÄØ¬∑‚ÄØFiltering Rows with `WHERE` \n",
    "\n",
    "Esimated time: 10 minutes\n",
    "\n",
    "### Learning Objective\n",
    "Learn how to filter data using WHERE clauses, including comparison operators, logical operators (AND, OR), and pattern matching with LIKE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8569fc",
   "metadata": {},
   "source": [
    "üîë **Key Concept:** Filtering\n",
    "\n",
    "Filtering is the process of selecting a subset of rows that match a certain condition. Think of it as answering the question \"Which rows do I want to keep?\"\n",
    "\n",
    "Filtering happens before selecting. This is at the crux of our desk-bookshelf analogy - we just want to query the data that we will be needing, so that it is manageable when it gets to our desk.\n",
    "\n",
    "\n",
    "**üìö Real-World Applications**\n",
    "- Finding transactions above a certain amount for audit <br>\n",
    "- Filtering customer data by region for targeted marketing<br>\n",
    "- Identifying high-value products for inventory management<br>\n",
    "- Finding recent orders for shipping prioritization<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccd7f88-bdf1-46c7-996f-7d77c238fe22",
   "metadata": {},
   "source": [
    "The basic filtering method is WHERE, and the syntax is as follows:\n",
    "\n",
    "```sql\n",
    "SELECT columns\n",
    "FROM table\n",
    "WHERE condition\n",
    "\n",
    "```\n",
    "\n",
    "As we will see in a bit, the conditions we can impose are very flexible. But, as a first example, let's filter our previous database to those consumers who purchased more than one item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0301cf2-8ceb-478a-b6a5-827771ffe791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers who purchased more than one item:\n",
      "                name         city  items_purchased  price_per_item\n",
      "0       Maria Garcia       London             15.0             NaN\n",
      "1             Li Wei        Tokyo             11.0           14.18\n",
      "2         Emma Brown        Paris              8.0           64.68\n",
      "3       Ahmed Hassan       Sydney              7.0           25.35\n",
      "4      Sarah Johnson       Berlin             19.0           15.85\n",
      "5   Carlos Rodriguez       Mumbai             11.0           95.40\n",
      "6      Anna Kowalski    S√£o Paulo             11.0           96.91\n",
      "7       James Wilson      Toronto              4.0           82.76\n",
      "8        Yuki Tanaka     Shanghai              8.0           37.42\n",
      "9        Elena Popov       Madrid              3.0           18.79\n",
      "10     Michel Dubois       Moscow              2.0           71.58\n",
      "11      Sofia Santos        Dubai             12.0           49.61\n",
      "12     Lars Andersen         None              6.0           20.98\n",
      "13       Aisha Patel  Mexico City              2.0           54.57\n",
      "14         Lucy Chen        Cairo             12.0           91.84\n",
      "15       Ivan Petrov    Stockholm             12.0           33.29\n",
      "16     Mary Williams         None             17.0           69.63\n",
      "17         Raj Kumar  Los Angeles             10.0           38.05\n",
      "18      Hans Schmidt         Rome             16.0             NaN\n",
      "19    Isabella Silva    Hong Kong             15.0           59.20\n",
      "20          Jun Park        Seoul             19.0           97.26\n",
      "21      Anna Ivanova      Bangkok             12.0           79.76\n"
     ]
    }
   ],
   "source": [
    "# Customers who purchased more than one item\n",
    "where_query = \"\"\"\n",
    "SELECT name, city, items_purchased, price_per_item\n",
    "FROM customers\n",
    "WHERE items_purchased > 1\n",
    "\"\"\"\n",
    "result = pd.read_sql_query(where_query, conn)\n",
    "print(\"Customers who purchased more than one item:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138a89b7-c0a0-4acd-8e6a-f2cd700e18f2",
   "metadata": {},
   "source": [
    "This example actually shows something very interesting about the ```WHERE``` statement - we don't need to keep the column we are using to filter the rows.\n",
    "\n",
    "In other words, let's say that we don't care too much about how much an user actually purchase, but we only want those who spend above a threshold. We can use ```WHERE``` combined with ```SELECT``` to use the information for filtering, but not keep it with us after it has been used, saving a lot of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f58621-700f-4569-b70e-005520d37886",
   "metadata": {},
   "source": [
    "ü•ä **Challenge:** List the `name`, `country`, and `age` of all customers **older than 50** who live in **Brazil**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7ee135-2d11-434f-a455-c135c89941ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will raise a sqlite3.OperationalError ‚Äî fix it!\n",
    "bad_query = \"\"\"\n",
    "SELECT name country age\n",
    "FROM customers\n",
    "WHERE age > 50\n",
    "  country = 'Brazil';\n",
    "\"\"\"\n",
    "pd.read_sql_query(bad_query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eccfd4",
   "metadata": {},
   "source": [
    "### 6.1 Filtering Methods\n",
    "\n",
    "Here are some commonly used filtering methods:\n",
    "\n",
    "1. **Equality / inequality**  \n",
    "   ```sql\n",
    "   ‚Ä¶ WHERE country = 'Germany';\n",
    "   ```\n",
    "‚ö†Ô∏è **Warning:** Be careful with string comparisons - they might be case-sensitive depending on the SQL engine and version you are using.\n",
    "\n",
    "2. **Set membership**  \n",
    "   ```sql\n",
    "   ‚Ä¶ WHERE country IN ('USA','UK','Germany');\n",
    "   ```\n",
    "\n",
    "3. **Comparison**  \n",
    "   ```sql\n",
    "   ‚Ä¶ WHERE freight > 100;\n",
    "   ```\n",
    "\n",
    "üìù **Poll 4:** Which comparison operator would you use to find values in a specific range?\n",
    "\n",
    "4. **NULL checks**  \n",
    "   ```sql\n",
    "   ‚Ä¶ WHERE fax IS NULL;\n",
    "   ```\n",
    "\n",
    "‚ö†Ô∏è **Warning:** When you compare anything to NULL, the result isn't TRUE or FALSE, it is a special third type called UNKNOWN. \n",
    "\n",
    "This feature can be quite confusing, especially in the beginning. A common mistake is to try to find rows with missing values by using \n",
    "\n",
    "'WHERE column = NULL'\n",
    "\n",
    "This leads to the comparison  `NULL` **‚â†** `NULL` , which yields *UNKNOWN*, rather than TRUE.\n",
    "\n",
    "In SQL, we should instead use dedicated functions:\n",
    "\n",
    "```sql\n",
    "‚Ä¶ WHERE fax IS NULL\n",
    "‚Ä¶ WHERE fax IS NOT NULL\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4ea13a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>‚ö†Ô∏è Other common WHERE mistakes</b><br><br>\n",
    "\n",
    "1. String matching\n",
    "   - ‚ùå Forgetting quotes: `WHERE name = John`\n",
    "   - ‚úÖ Using quotes: `WHERE name = 'John'`\n",
    "\n",
    "2. Date comparisons\n",
    "   - ‚ùå `WHERE date >= '2024-01-01'` AND `date <= '2024-12-31'` \n",
    "   - ‚úÖ `WHERE date >= '2024-01-01'` AND `date < '2025-01-01'`\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b864978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect NULL check (city = NULL):\n",
      "Empty DataFrame\n",
      "Columns: [name, city]\n",
      "Index: []\n",
      "Correct NULL check (city IS NULL):\n",
      "            name  city country\n",
      "0  Lars Andersen  None    None\n",
      "1  Mary Williams  None    None\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating NULL handling with our customers data\n",
    "# First, the incorrect way\n",
    "incorrect_null_query = \"\"\"\n",
    "SELECT name, city\n",
    "FROM customers\n",
    "WHERE city = NULL\n",
    "\"\"\"\n",
    "print(\"Incorrect NULL check (city = NULL):\")\n",
    "print(pd.read_sql_query(incorrect_null_query, conn))\n",
    "\n",
    "# Now the correct way\n",
    "correct_null_query = \"\"\"\n",
    "SELECT name, city, country\n",
    "FROM customers\n",
    "WHERE city IS NULL\n",
    "\"\"\"\n",
    "print(\"Correct NULL check (city IS NULL):\")\n",
    "print(pd.read_sql_query(correct_null_query, conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fdf0eb-c0c0-4d25-94a6-cb5634888124",
   "metadata": {},
   "source": [
    "### 6.2 Multiple Conditions\n",
    "We can combine multiple conditions using logical operators:\n",
    "\n",
    "- AND: Both conditions must be true\n",
    "- OR: At least one condition must be true\n",
    "- NOT: Reverses a condition\n",
    "Use parentheses to make the order of operations clear:\n",
    "\n",
    "```sql\n",
    "WHERE (country = 'US' OR country = 'GB')\n",
    "  AND account_balance > 200\n",
    "```\n",
    "\n",
    "\n",
    "üí° **Tip:** You can combine multiple logical expressions using AND/OR/NOT. When doing so, use parentheses to clarify when one logical expressions begins and the other ends.\n",
    "‚ö†Ô∏è **Warning:** Without parentheses, AND takes precedence over OR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c103574",
   "metadata": {},
   "source": [
    "<a id='groupby'></a>\n",
    "## 7‚ÄØ¬∑‚ÄØAggregate Functions & `GROUP BY` \n",
    "\n",
    "Estimated Time: 25 minutes\n",
    "\n",
    "### Learning Objective\n",
    "Master data aggregation and grouping using SQL's aggregate functions (COUNT, SUM, AVG, etc.) and GROUP BY clause to analyze and summarize data effectively.\n",
    "\n",
    "### Real World Application  \n",
    "Given a list of individual transactions, calculate total sales per region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd18089-cd28-4048-b140-d4d8edf4b57f",
   "metadata": {},
   "source": [
    "### 7.1 The Basic Idea\n",
    "\n",
    "Another way of pre-processing data so that the end result is more manageable is to summarize it according to a given statistic.\n",
    "\n",
    "One common example is the use of aggreggate functions, combined with GROUP BY, to collapse many rows into one, while keeping the information contained in them, only now summarized in a single row.\n",
    "\n",
    "First let's understand what the ```GROUP BY``` statement does: it creates subsets of the entire table that are similar in a given way. The most common way of doing so is to pass a column - and then SQL will automatically group the rows according to the values in that column\n",
    "\n",
    "Second, ```GROUP BY``` statements are used in conjunction with aggreggate functions. By grouping rows according to a given column, we can guarantee that the values of these rows match **for that particular column**. But what about the others? They might be different, in which case there is no obvious way of combining them. Aggregate functions do exactly this - they tell SQL what to do with mismatching information inside the group - for example by counting the number of occurrences, summing or taking averages:\n",
    "\n",
    "```sql\n",
    "SELECT country,\n",
    "       COUNT(*)        AS n_orders,\n",
    "       ROUND(AVG(freight),2) AS avg_freight\n",
    "FROM   orders\n",
    "GROUP  BY country\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f9ea5a-65e2-443f-9f9d-cdc9aae7b874",
   "metadata": {},
   "source": [
    "![Three-step graphic: raw sales rows, grouped by Department, then totals‚Äîillustrates how GROUP BY collapses data.](../Images/groupby.svg) \n",
    "\n",
    "Let's break it down what is going on with the GROUP BY command.\n",
    "\n",
    "- First, SQL will look into the column indicated on GROUP BY - in this case \"department\"\n",
    "- It will then create buckets given the entries in this column. In other words, for each possible value in this column, it will group the rows based on these values.\n",
    "- For each of these groups, it will run an aggregate function - in this case COUNT(*), which counts how many entries each group has, and SUM(salary), which will sum the column salary across all rows in a given group\n",
    "- It will finally return the values of each group, and of the aggregate functions. Notice that each group only has one row in the resulting column - we have \"collapsed\" the table!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d3baf6-d850-43d3-9328-33bf0187b288",
   "metadata": {},
   "source": [
    "ü•ä **Challenge:** For each country, list the number of customers (COUNT(*)) and the total items purchased (SUM(items_purchased)).\n",
    "Show only countries with at least 5 customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a2e70c-e6e3-4c94-aa94-998b9fcb22d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug this intentional error\n",
    "\n",
    "bad_query = \"\"\"\n",
    "SELECT country,\n",
    "       COUNT(*),                       \n",
    "       SUM(items_purchased)\n",
    "FROM customers\n",
    "WHERE COUNT(*) >= 5                    \n",
    "GROUP BY country;\n",
    "\"\"\"\n",
    "pd.read_sql_query(bad_query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de76ed3-1bfa-41bc-b853-ae3e47c775df",
   "metadata": {},
   "source": [
    "### 7.2 More Advanced Ideas\n",
    "Another very important thing - which is a bit tough to get used to in the beginning, is that we can only include in the SELECT statement columns that are either used to group by observations, or ones that are used as inputs of aggregate functions. This is exactly because of what we discussed previously - if there is a mismatch between rows, SQL doesn't know how to handle these values when it collapses all the rows in the group into a single one.\n",
    "\n",
    "A bit more advanced, but we can also pass more than one column to the GROUP BY statement - which would then create groups in which rows have the same values for all columns passed.\n",
    "\n",
    "üí° **Tip**: By using GROUP BY, we obtain a collapsed version of the table - we only retain information on the aggregate values. While this is very useful for summarizing information, sometimes we want to keep the detailed data and the summary statistics for more in-depth analysis. This is exactly the problem that Window Functions solve - and something we will be dealing with in the intermediate workshop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bd53d24-3eac-469a-b62b-02ce1a4f2d61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer statistics by country:\n",
      "\n",
      "   country  customer_count  avg_items  avg_balance  max_balance\n",
      "0       AE               1       12.0       352.84       352.84\n",
      "1       AU               1        7.0       179.64       179.64\n",
      "2       BR               1       11.0       392.80       392.80\n",
      "3       CA               1        4.0       449.81       449.81\n",
      "4       CN               1        8.0       344.21       344.21\n",
      "5       DE               1       19.0          NaN          NaN\n",
      "6       EG               1       12.0       167.10       167.10\n",
      "7       ES               1        3.0       845.86       845.86\n",
      "8       FR               1        8.0       929.69       929.69\n",
      "9       GB               1       15.0       905.34       905.34\n",
      "10      HK               1       15.0       833.92       833.92\n",
      "11      IN               1       11.0       140.70       140.70\n",
      "12      IT               1       16.0       104.97       104.97\n",
      "13      JP               1       11.0       638.11       638.11\n",
      "14      KR               1       19.0       756.11       756.11\n",
      "15      MX               1        2.0       226.83       226.83\n",
      "16      NL               1        1.0       821.98       821.98\n",
      "17      RU               1        2.0       421.08       421.08\n",
      "18      SE               1       12.0       988.20       988.20\n",
      "19      TH               1       12.0       794.14       794.14\n",
      "20      TR               1        NaN       736.17       736.17\n",
      "21      US               2       10.0       945.55       945.55\n"
     ]
    }
   ],
   "source": [
    "# GROUP BY country with aggregations\n",
    "group_by_query = \"\"\"\n",
    "SELECT \n",
    "    country,\n",
    "    COUNT(*) AS customer_count,\n",
    "    ROUND(AVG(items_purchased), 2) AS avg_items,\n",
    "    ROUND(AVG(account_balance), 2) AS avg_balance,\n",
    "    ROUND(MAX(account_balance), 2) AS max_balance\n",
    "FROM customers\n",
    "WHERE country IS NOT NULL\n",
    "GROUP BY country\n",
    "\"\"\"\n",
    "result = pd.read_sql_query(group_by_query, conn)\n",
    "print(\"Customer statistics by country:\\n\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4d0eb1-1862-4d94-a06a-d2e663b4bb3c",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è Warning: Common Mistake - Using aggregate functions without GROUP BY\n",
    "\n",
    "```sql\n",
    "-- ‚ùå WRONG: Mixing aggregate and non-aggregate columns\n",
    "SELECT country, COUNT(*), AVG(account_balance)\n",
    "FROM customers\n",
    "\n",
    "-- ‚úÖ CORRECT: Add GROUP BY for non-aggregate columns\n",
    "SELECT country, COUNT(*), AVG(account_balance)\n",
    "FROM customers\n",
    "GROUP BY country\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf7be3e-f54d-4edf-aeee-50e8101b7ae0",
   "metadata": {},
   "source": [
    "### 7.3: Summarizing\n",
    "\n",
    "Key points:\n",
    "\n",
    "- Every non-aggregated column in SELECT must be in GROUP BY\n",
    "- GROUP BY comes after WHERE but before ORDER BY\n",
    "- Can group by multiple columns\n",
    "- Can use expressions in GROUP BY \n",
    "\n",
    "For future reference, here is a list of the most commonly used aggregate functions:\n",
    "\n",
    "| Aggregate¬†Function                                   | What it returns (typical usage)                    |\n",
    "| ---------------------------------------------------- | -------------------------------------------------- |\n",
    "| `COUNT(*)`                                           | Total number of rows in the group/query            |\n",
    "| `SUM(col)`                                           | Arithmetic sum of a numeric column                 |\n",
    "| `AVG(col)`                                           | Mean (average) of numeric values                   |\n",
    "| `MAX(col)`                                           | Largest value (numeric *or* lexicographic)         |\n",
    "| `MIN(col)`                                           | Smallest value (numeric *or* lexicographic)        |\n",
    "| `STRING_AGG(col, ', ')` / `GROUP_CONCAT` / `LISTAGG` | Concatenates strings in the group with a delimiter |\n",
    "| `COUNT(DISTINCT col)`                                | Count of unique, non-NULL values                   |\n",
    "\n",
    "üí° **Tip**: Mathematical functions ignore `NULL` in aggregates (`AVG`, `SUM`), which is usually what you want. `COUNT(column)` counts only non‚Äënull values, whereas `COUNT(*)` counts *all* rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce8b27d-9739-4b0c-99d5-dfd95bcaa12c",
   "metadata": {},
   "source": [
    "### 7.4‚ÄØ¬∑‚ÄØFiltering Groups with `HAVING` \n",
    "\n",
    "Remember that when we discussed filtering, we used the WHERE command, which was run before the ```GROUP BY```.\n",
    "\n",
    "Sometimes, we want to filter rows given an aggregate statement. For example, we might want to choose only the customers whose average expenditure is larger than a certain amount.\n",
    "\n",
    "`HAVING` is evaluated **after** grouping ‚Äì it filters *groups*, whereas `WHERE` filters *rows*.\n",
    "\n",
    "Two Observations:\n",
    "- We cannot use aggregate functions on ```WHERE``` statements\n",
    "- We must use ```HAVING``` after the ```GROUP BY``` statement\n",
    "\n",
    "```sql\n",
    "SELECT country,\n",
    "       COUNT(*) AS n_orders\n",
    "FROM   orders\n",
    "GROUP  BY country\n",
    "HAVING n_orders > 20          -- aggregate in condition\n",
    "ORDER  BY n_orders DESC;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "935ebc58-21b3-4fd7-b58a-08c167eb13ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries with average purchases > 5 and at least 2 customers:\n",
      "Empty DataFrame\n",
      "Columns: [country, customer_count, avg_items_purchased, avg_balance]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Countries with high average purchases using HAVING\n",
    "having_query = \"\"\"\n",
    "SELECT \n",
    "    country,\n",
    "    COUNT(*) AS customer_count,\n",
    "    ROUND(AVG(items_purchased), 2) AS avg_items_purchased,\n",
    "    ROUND(AVG(account_balance), 2) AS avg_balance\n",
    "FROM customers\n",
    "WHERE country IS NOT NULL \n",
    "  AND items_purchased IS NOT NULL\n",
    "GROUP BY country\n",
    "HAVING AVG(items_purchased) > 5 \n",
    "   AND COUNT(*) >= 2\n",
    "\"\"\"\n",
    "result = pd.read_sql_query(having_query, conn)\n",
    "print(\"Countries with average purchases > 5 and at least 2 customers:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d116b3ac-d82b-45e0-86f2-f24c9ae7d7b9",
   "metadata": {},
   "source": [
    "![Split-path illustration contrasting filtering rows with WHERE before grouping versus HAVING after aggregation.](../Images/wherehaving.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabe9abf-8d57-4507-a1c4-2a98f0378f13",
   "metadata": {},
   "source": [
    "üôã **Hands-Up:** Can you explain‚Äîin one sentence‚Äîwhat `HAVING` does that `WHERE` can‚Äôt? A. Yes‚ÄÉB. Not yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f02a85",
   "metadata": {},
   "source": [
    "<a id='orderby'></a>\n",
    "## 8‚ÄØ¬∑‚ÄØSorting & Paginating Results \n",
    "\n",
    "Estimate Time: 10 minutes\n",
    "\n",
    "### Real World Application: \n",
    "\n",
    "Find the top 10 selling items on a given year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae469c7c-8110-4642-bd22-b2af888c5648",
   "metadata": {},
   "source": [
    "After we have processed our data, we might want to start preparing it for visualization. In SQL, this is done mostly through sorting - ordering the data according to one or more columns - or paginating - retrieving only a fixed number of observations\n",
    "\n",
    "`ORDER¬†BY` is evaluated *after* `SELECT`.  \n",
    "\n",
    "* Default sort is **ASC** (ascending).  \n",
    "* Use **DESC** for descending order.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "810def20-e967-457e-ba60-77cf835b6d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple ORDER BY Example - Top 10 Customers by Items Purchased:\n",
      "\n",
      "                name         city  items_purchased\n",
      "0      Sarah Johnson       Berlin             19.0\n",
      "1           Jun Park        Seoul             19.0\n",
      "2      Mary Williams         None             17.0\n",
      "3       Hans Schmidt         Rome             16.0\n",
      "4       Maria Garcia       London             15.0\n",
      "5     Isabella Silva    Hong Kong             15.0\n",
      "6       Sofia Santos        Dubai             12.0\n",
      "7          Lucy Chen        Cairo             12.0\n",
      "8        Ivan Petrov    Stockholm             12.0\n",
      "9       Anna Ivanova      Bangkok             12.0\n",
      "10            Li Wei        Tokyo             11.0\n",
      "11  Carlos Rodriguez       Mumbai             11.0\n",
      "12     Anna Kowalski    S√£o Paulo             11.0\n",
      "13         Raj Kumar  Los Angeles             10.0\n",
      "14        Emma Brown        Paris              8.0\n",
      "15       Yuki Tanaka     Shanghai              8.0\n",
      "16      Ahmed Hassan       Sydney              7.0\n",
      "17     Lars Andersen         None              6.0\n",
      "18      James Wilson      Toronto              4.0\n",
      "19       Elena Popov       Madrid              3.0\n",
      "20     Michel Dubois       Moscow              2.0\n",
      "21       Aisha Patel  Mexico City              2.0\n",
      "22    Diego Martinez    Amsterdam              1.0\n"
     ]
    }
   ],
   "source": [
    "# Simple ORDER BY example with one column\n",
    "simple_order_query = \"\"\"\n",
    "SELECT \n",
    "   name,\n",
    "   city,\n",
    "   items_purchased\n",
    "FROM customers\n",
    "WHERE items_purchased IS NOT NULL\n",
    "ORDER BY items_purchased DESC\n",
    "\"\"\"\n",
    "\n",
    "print(\"Simple ORDER BY Example - Top 10 Customers by Items Purchased:\\n\")\n",
    "result = pd.read_sql_query(simple_order_query, conn)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55280696-136d-4238-8b09-f34dc966e44c",
   "metadata": {},
   "source": [
    "You can order by *multiple* columns ‚Äì the second acts as a tie‚Äëbreaker.\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "       name,\n",
    "       country,\n",
    "       total_spent,\n",
    "       ROW_NUMBER() OVER (\n",
    "           PARTITION BY country\n",
    "           ORDER BY total_spent DESC,   -- primary\n",
    "                    name               -- secondary tie-breaker\n",
    "       ) AS spend_rank\n",
    "FROM   customer_spending;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a938f7d5-3cef-485b-a9fe-ce65aa41bf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORDER BY Example - Sorting by Country then Balance:\n",
      "            name country  account_balance\n",
      "0  Mary Williams    None           795.02\n",
      "1  Lars Andersen    None           588.43\n",
      "2   Sofia Santos      AE           352.84\n",
      "3   Ahmed Hassan      AU           179.64\n",
      "4  Anna Kowalski      BR           392.80\n",
      "5   James Wilson      CA           449.81\n",
      "6    Yuki Tanaka      CN           344.21\n",
      "7      Lucy Chen      EG           167.10\n",
      "8    Elena Popov      ES           845.86\n",
      "9     Emma Brown      FR           929.69\n"
     ]
    }
   ],
   "source": [
    "# Example showing ORDER BY with multiple columns\n",
    "order_by_example = \"\"\"\n",
    "SELECT \n",
    "   name,\n",
    "   country,\n",
    "   account_balance\n",
    "FROM customers\n",
    "WHERE account_balance IS NOT NULL\n",
    "ORDER BY country ASC, account_balance DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "print(\"ORDER BY Example - Sorting by Country then Balance:\")\n",
    "result = pd.read_sql_query(order_by_example, conn)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3222d1e",
   "metadata": {},
   "source": [
    "\n",
    "### Pagination Pattern\n",
    "\n",
    "LIMIT is used to restrict how many observations we want to retrieve <br>\n",
    "OFFSET will skill a certain number of rows before displaying the number of results delimited by LIMIT\n",
    "\n",
    "\n",
    "```sql\n",
    "SELECT company_name, country, city\n",
    "FROM   customers\n",
    "ORDER  BY country\n",
    "LIMIT  n\n",
    "OFFSET m;\n",
    "```\n",
    "\n",
    "`LIMIT` must appear *before* `OFFSET` in SQLite.\n",
    "\n",
    "‚ö†Ô∏è **Warning:** It is very hard to predict what the ordering will be after applying filtering or other methods. So remember to always ORDER BY before using LIMIT/OFFSET!\n",
    "\n",
    "üí° **Tip**: Interestingly, LIMIT doesn't restrict the data being retrived by SQL, only the data being showed. The difference is crucial to understand when thinking about factors such as speed, memory constraints and computing budgeting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a668312",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers ranked 6-10 by account balance:\n",
      "\n",
      "             name country  account_balance\n",
      "0  Isabella Silva      HK           833.92\n",
      "1  Diego Martinez      NL           821.98\n",
      "2   Mary Williams    None           795.02\n",
      "3    Anna Ivanova      TH           794.14\n",
      "4        Jun Park      KR           756.11\n"
     ]
    }
   ],
   "source": [
    "# Sorting and pagination example\n",
    "pagination_query = \"\"\"\n",
    "SELECT \n",
    "    name,\n",
    "    country,\n",
    "    account_balance\n",
    "FROM customers\n",
    "WHERE account_balance IS NOT NULL\n",
    "ORDER BY account_balance DESC\n",
    "LIMIT 5\n",
    "OFFSET 5;\n",
    "\"\"\"\n",
    "result = pd.read_sql_query(pagination_query, conn)\n",
    "print(\"Customers ranked 6-10 by account balance:\\n\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5a8432-3f9c-446c-be8a-deb5008cbffc",
   "metadata": {},
   "source": [
    "üôã **Hands-Up:** Which clause actually *sorts* the result set? A. `SELECT`‚ÄÉB. `ORDER BY`‚ÄÉC. `LIMIT`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5c7fb5-1e02-4c70-8433-49b3b780e080",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è Warning: Common Mistake - Wrong clause order\n",
    "\n",
    "-- ‚ùå WRONG: ORDER BY must come before LIMIT\n",
    "```sql\n",
    "SELECT * FROM customers\n",
    "LIMIT 10\n",
    "ORDER BY account_balance DESC \n",
    "```\n",
    "\n",
    "-- ‚úÖ CORRECT: Proper SQL clause order\n",
    "```sql\n",
    "SELECT * FROM customers\n",
    "ORDER BY account_balance DESC\n",
    "LIMIT 10 ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2094a318-876c-4b39-b2e1-10c568067e98",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "We learned quite a few different commands for queries. Let's see one example that includes all of them:\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "    Country,\n",
    "    COUNT(OrderID)                AS total_orders,\n",
    "    ROUND(AVG(Freight), 2)        AS avg_freight\n",
    "FROM    customers \n",
    "WHERE   Country IN ('USA','UK','Germany')\n",
    "GROUP BY Country\n",
    "HAVING   COUNT(OrderID) >= 10\n",
    "ORDER BY total_orders DESC\n",
    "LIMIT 5;\n",
    "```\n",
    "\n",
    "The diagram reiterates the **logical query order**, not the command order, helping you remember the order in which the operations are actually made.\n",
    "\n",
    "![Horizontal flowchart listing SQL clause execution order: FROM ‚Üí WHERE ‚Üí GROUP BY ‚Üí HAVING ‚Üí SELECT ‚Üí ORDER BY ‚Üí LIMIT](../Images/sql-execution-order.svg)\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1e8bb1-5c3c-40ae-9538-84a635a5febc",
   "metadata": {},
   "source": [
    "### A visualization of the order of query operations\n",
    "\n",
    "Let's go through an example of how the order of query operations look like in practice. \n",
    "\n",
    "**FROM¬†`customers`** ‚Äì full table (7¬†rows).\n",
    "\n",
    "| CustID | Country | Orders |\n",
    "|-------|---------|--------|\n",
    "| C1 | USA | 5 |\n",
    "| C2 | USA | 7 |\n",
    "| C3 | UK  | 3 |\n",
    "| C4 | UK  | 7 |\n",
    "| C5 | FRA | 15 |\n",
    "| C6 | GER | 2 |\n",
    "| C7 | CAN | 6 |\n",
    "\n",
    "---\n",
    "\n",
    "**WHERE¬†`Country IN ('USA','UK','FRA','GER')`** ‚Äì drop the Canadian row.\n",
    "\n",
    "| CustID | Country | Orders |\n",
    "|-------|---------|--------|\n",
    "| C1 | USA | 5 |\n",
    "| C2 | USA | 7 |\n",
    "| C3 | UK  | 3 |\n",
    "| C4 | UK  | 7 |\n",
    "| C5 | FRA | 15 |\n",
    "| C6 | GER | 2 |\n",
    "\n",
    "---\n",
    "\n",
    "**GROUP¬†BY¬†`Country`** ‚Äì aggregate rows, summing `Orders` - Drops CustID!\n",
    "\n",
    "| Country | TotalOrders |\n",
    "|---------|-------------|\n",
    "| USA | 12 |\n",
    "| UK  | 10 |\n",
    "| FRA | 15 |\n",
    "| GER | 2  |\n",
    "\n",
    "---\n",
    "\n",
    "**HAVING¬†`TotalOrders > 5`** ‚Äì keep only groups with large order volume; Germany drops out.\n",
    "\n",
    "| Country | TotalOrders |\n",
    "|---------|-------------|\n",
    "| FRA | 15 |\n",
    "| USA | 12 |\n",
    "| UK  | 10 |\n",
    "\n",
    "---\n",
    "\n",
    "**SELECT¬†`Country, TotalOrders`** ‚Äì project just the columns we care about (already those two).\n",
    "\n",
    "| Country | TotalOrders |\n",
    "|---------|-------------|\n",
    "| FRA | 15 |\n",
    "| USA | 12 |\n",
    "| UK  | 10 |\n",
    "\n",
    "---\n",
    "\n",
    "**ORDER¬†BY¬†`TotalOrders DESC`** ‚Äì rank countries by order volume.\n",
    "\n",
    "| Country | TotalOrders |\n",
    "|---------|-------------|\n",
    "| FRA | 15 |\n",
    "| USA | 12 |\n",
    "| UK  | 10 |\n",
    "\n",
    "---\n",
    "\n",
    "**LIMIT¬†2** ‚Äì return only the top two performers.\n",
    "\n",
    "| Country | TotalOrders |\n",
    "|---------|-------------|\n",
    "| FRA | 15 |\n",
    "| USA | 12 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f5fa8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "<a id='keypoints'></a>\n",
    "<div class=\"alert alert-success\">  \n",
    "    \n",
    "## 11‚ÄØ¬∑‚ÄØKey Points & Next Steps \n",
    "\n",
    "Estimate Time: 2 minutes\n",
    "\n",
    "* Use SQL to select and pre-process only the data you really need, then use this smaller dataset for analysis with pandas\n",
    "* SQLite is a zero‚Äëinstall, single‚Äëfile engine that still speaks standard SQL.  \n",
    "* Remember the logical query order to avoid confusion (`WHERE` vs `HAVING`).  \n",
    "\n",
    "### What‚Äôs Next?  \n",
    "In the **Intermediate SQL** workshop we will tackle:\n",
    "\n",
    "* Creating & altering tables  \n",
    "* `JOIN`s (```INNER```, ```LEFT```, ```RIGHT```, ```FULL```) and set operations\n",
    "* `JOIN` as selection  \n",
    "* Subqueries & Common Table Expressions (`WITH`)  \n",
    "* Window functions (`ROW_NUMBER`, `LAG`, `LEAD`)  \n",
    "* ```UNION```\n",
    "* Pivoting\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d82f06-d014-4671-8958-fd59bd9a6d68",
   "metadata": {},
   "source": [
    "## üé¨ Demo ‚Äî Customer Spending vs. Income Ranking  \n",
    "\n",
    "üí° **Goal**  \n",
    "Show how window functions, CTEs, and JOINs can be combined to answer a practical business question:\n",
    "\n",
    "> *‚ÄúHow much does each customer spend relative to the income they report?‚Äù*\n",
    "\n",
    "### What the query does\n",
    "1. **`customer_spending` CTE**  \n",
    "   *Calculates* each customer‚Äôs total spending (`items_purchased √ó price_per_item`).\n",
    "\n",
    "2. **`income_ranking` CTE**  \n",
    "   Aggregates income **and** ranks customers by `SUM(amount)` using  \n",
    "   `RANK() OVER (ORDER BY total_income DESC)`.\n",
    "\n",
    "3. **Main SELECT**  \n",
    "   *Joins* the two CTEs on `name` and computes  \n",
    "   **`spending_pct_of_income`** = spending √∑ income √ó 100.\n",
    "\n",
    "Run the cell below and inspect the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbd6e6ee-1726-4d00-b46a-d57be792b48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ DEMO: Customer Spending Analysis with Income Ranking\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>total_spent</th>\n",
       "      <th>total_income</th>\n",
       "      <th>income_rank</th>\n",
       "      <th>spending_pct_of_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahmed Hassan</td>\n",
       "      <td>177.45</td>\n",
       "      <td>5800.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lars Andersen</td>\n",
       "      <td>125.88</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yuki Tanaka</td>\n",
       "      <td>299.36</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>8</td>\n",
       "      <td>9.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diego Martinez</td>\n",
       "      <td>13.09</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elena Popov</td>\n",
       "      <td>56.37</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mary Williams</td>\n",
       "      <td>1183.71</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>13</td>\n",
       "      <td>98.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sarah Johnson</td>\n",
       "      <td>301.15</td>\n",
       "      <td>400.0</td>\n",
       "      <td>14</td>\n",
       "      <td>75.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Li Wei</td>\n",
       "      <td>155.98</td>\n",
       "      <td>200.0</td>\n",
       "      <td>15</td>\n",
       "      <td>77.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  total_spent  total_income  income_rank  \\\n",
       "0    Ahmed Hassan       177.45        5800.0            1   \n",
       "1   Lars Andersen       125.88        4500.0            2   \n",
       "2     Yuki Tanaka       299.36        3200.0            8   \n",
       "3  Diego Martinez        13.09        2700.0           10   \n",
       "4     Elena Popov        56.37        1800.0           12   \n",
       "5   Mary Williams      1183.71        1200.0           13   \n",
       "6   Sarah Johnson       301.15         400.0           14   \n",
       "7          Li Wei       155.98         200.0           15   \n",
       "\n",
       "   spending_pct_of_income  \n",
       "0                    3.06  \n",
       "1                    2.80  \n",
       "2                    9.36  \n",
       "3                    0.48  \n",
       "4                    3.13  \n",
       "5                   98.64  \n",
       "6                   75.29  \n",
       "7                   77.99  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DEMO: Combining Window Functions with JOIN\n",
    "income_df = pd.read_sql_query('SELECT * FROM income', conn)\n",
    "\n",
    "demo_query = \"\"\"\n",
    "WITH customer_spending AS (\n",
    "    SELECT \n",
    "        name,\n",
    "        items_purchased * price_per_item AS total_spent\n",
    "    FROM customers\n",
    "    WHERE items_purchased IS NOT NULL \n",
    "      AND price_per_item IS NOT NULL\n",
    "),\n",
    "income_ranking AS (\n",
    "    SELECT \n",
    "        name,\n",
    "        SUM(amount) AS total_income,\n",
    "        RANK() OVER (ORDER BY SUM(amount) DESC) AS income_rank\n",
    "    FROM income\n",
    "    WHERE amount IS NOT NULL\n",
    "    GROUP BY name\n",
    ")\n",
    "SELECT \n",
    "    cs.name,\n",
    "    cs.total_spent,\n",
    "    ir.total_income,\n",
    "    ir.income_rank,\n",
    "    CASE \n",
    "        WHEN ir.total_income > 0 \n",
    "        THEN ROUND(cs.total_spent * 100.0 / ir.total_income, 2)\n",
    "        ELSE NULL \n",
    "    END AS spending_pct_of_income\n",
    "FROM customer_spending cs\n",
    "JOIN income_ranking ir ON cs.name = ir.name\n",
    "ORDER BY ir.income_rank;\n",
    "\"\"\"\n",
    "\n",
    "print(\"üé¨ DEMO: Customer Spending Analysis with Income Ranking\\n\")\n",
    "display(pd.read_sql_query(demo_query, conn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e48856-15c7-4e1b-8c6c-823fca1f9880",
   "metadata": {},
   "source": [
    "üôã **Hands-Up:** How was that exercise? A. Easy‚ÄÉB. Okay‚ÄÉC. Tough"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
