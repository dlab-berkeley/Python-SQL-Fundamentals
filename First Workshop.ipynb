{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe48a7aa",
   "metadata": {},
   "source": [
    "# SQL for Data Analysis  \n",
    "### Introductory Workshop\n",
    "*D‚ÄëLab, UC¬†Berkeley*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69798bf",
   "metadata": {},
   "source": [
    "## Table of Contents  \n",
    "1. [Why SQL?](#why-sql)\n",
    "3. [Relational Databases](#relational)    \n",
    "4. [Importing CSV ‚Üí SQLite](#sqlite)  \n",
    "5. [SQLite Data Types & NULLs](#types)  \n",
    "6. [SELECT & Derived Columns](#select)  \n",
    "7. [Filtering Rows with WHERE](#where)  \n",
    "8. [Sorting & Paging Results](#orderby)  \n",
    "9. [Aggregates & GROUP¬†BY](#groupby)  \n",
    "10. [Filtering Groups with HAVING](#having)  \n",
    "11. [Key Points & Next Steps](#keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c357b9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"> \n",
    "<b>Learning Goals</b><br><br>\n",
    "By the end of this workshop you will be able to:\n",
    "<ul>\n",
    "<li>Understand why one would use SQL and why and how it is complementary to Pandas</li>\n",
    "<li>Write basic queries with <code>SELECT</code>, create aliases, and build derived columns.</li>\n",
    "<li>Filter rows using <code>WHERE</code>, sort and paginate result sets with <code>ORDER¬†BY</code>, <code>LIMIT</code>, <code>OFFSET</code>.</li>\n",
    "<li>Summarise data with aggregates &nbsp;(<code>COUNT</code>, <code>SUM</code>, <code>AVG</code>, <code>MIN</code>, <code>MAX</code>)&nbsp; and <code>GROUP¬†BY</code>.</li>\n",
    "<li>Filter groups with <code>HAVING</code> and understand why it is different from <code>WHERE</code></li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7d556f-308a-42d0-8f4d-3e34434c0180",
   "metadata": {},
   "source": [
    "### Icons Used in This Notebook\n",
    "üîî **Question**: A quick question to help you understand what's going on.<br>\n",
    "ü•ä **Challenge**: Interactive exercise. We'll work through these in the workshop!<br>\n",
    "üí° **Tip**: How to do something a bit more efficiently or effectively.<br>\n",
    "‚ö†Ô∏è **Warning:** Heads-up about tricky stuff or common mistakes.<br>\n",
    "üìù **Poll:** A Zoom poll to help you learn!<br>\n",
    "üé¨ **Demo**: Showing off something more advanced ‚Äì so you know what Python can be used for!<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a03e0eb",
   "metadata": {},
   "source": [
    "<a id='why-sql'></a>\n",
    "## 1‚ÄØ¬∑‚ÄØWhy SQL? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1996907b-0e2b-4690-b367-786383cf8d0c",
   "metadata": {},
   "source": [
    "üìù **Poll:** What is the usual size of databases you use? How large do you think databases can get?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06897baf",
   "metadata": {},
   "source": [
    "### Bookcase¬†vs¬†Desk Analogy  \n",
    "Think of your computer‚Äôs RAM as the desk where you spread papers you‚Äôre actively working on, and the hard‚Äëdrive as the bookcase that stores all your books.\n",
    "\n",
    "Working at your desk is fast, but at the same time it doesn't hold nearly as much material as a bookshelf. So if you are working with very large datasets, you are at risk of overloading your desk with material. \n",
    "\n",
    "* **pandas** is excellent for analysis of *smaller* data that fits comfortably on the desk.  \n",
    "* **SQL** is the tool we use to selectively bring only the information we need from the bookcases to the desk.\n",
    "\n",
    "> **Example:** A 20‚ÄØGB transaction table can be grouped and aggregated with a single SQL statement, whereas pandas would first need 20‚ÄØGB of memory just to read the file.\n",
    "\n",
    "### Complement, not Substitutes \n",
    "In practice we often:\n",
    "\n",
    "1. Use SQL to slice/aggregate huge tables, producing a manageable result set  \n",
    "2. Pull that into pandas for plotting or modelling  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e70aa35",
   "metadata": {},
   "source": [
    "> **Poll¬†üöÄ**  How comfortable are you with SQL?  \n",
    "> - 0 ‚Äì Never used it  \n",
    "> - 1 ‚Äì Use a couple of SELECT statements  \n",
    "> - 2 ‚Äì Can write basic filters  \n",
    "> - 3 ‚Äì Confident with GROUP¬†BY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419f7c30",
   "metadata": {},
   "source": [
    "<a id='relational'></a>\n",
    "## 2‚ÄØ¬∑‚ÄØRelational Databases "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b4020f",
   "metadata": {},
   "source": [
    "## What is a Relational Database?\n",
    "\n",
    "A relational database organizes data into **tables** (sometimes called relations), which consist of rows and columns:\n",
    "\n",
    "- **Tables**: Collections of related data (e.g., Customers, Orders)\n",
    "- **Columns**: Specific attributes (e.g., CustomerID, FirstName)\n",
    "- **Rows**: Individual records in the table\n",
    "- **Primary Keys**: Unique identifiers for each row\n",
    "- **Foreign Keys**: References to primary keys in other tables that create relationships\n",
    "\n",
    "#### Example Schema\n",
    "\n",
    "| Table      | Columns |\n",
    "|----------- |-----------------------------|\n",
    "| **Customers** | __CustomerID__ (PK), CompanyName, Country |\n",
    "| **Orders**    | __OrderID__ (PK), OrderDate, **CustomerID** (FK) |\n",
    "\n",
    "> **Primary¬†Key vs Foreign¬†Key**  \n",
    "> ‚Ä¢ **Primary¬†Key (PK)**: Unique identifier for a row: Each row has one, and no two rows share one.  \n",
    "> ‚Ä¢ **Foreign¬†Key (FK)**: References the Primary Key of a different table, used to make connections between tables.\n",
    "\n",
    "**Sample rows**\n",
    "\n",
    "```text\n",
    "Customers\n",
    "+------------+--------------+---------+\n",
    "|CustomerID  |CompanyName   |Country  |\n",
    "+------------+--------------+---------+\n",
    "|ALFKI       |Alfreds Futter|Germany  |\n",
    "|ANATR       |Ana Trujillo  |Mexico   |\n",
    "+------------+--------------+---------+\n",
    "\n",
    "Orders\n",
    "+---------+------------+------------+\n",
    "|OrderID  |OrderDate   |CustomerID  |\n",
    "+---------+------------+------------+\n",
    "|10248    |1996‚Äë07‚Äë04  |VINET       |\n",
    "|10249    |1996‚Äë07‚Äë05  |TOMSP       |\n",
    "+---------+------------+------------+\n",
    "```\n",
    "\n",
    "These tables connect on `CustomerID`: each order ‚Äúbelongs‚Äù to exactly one customer - but notice that this is the Primary Key for the first table, and the Foregn Key for the second table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506d41e2-3cec-4474-83e0-7dbb105efffa",
   "metadata": {},
   "source": [
    "üìù **Poll 2:** Can you think of a table that would not have a Primary Key?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1a9e10-a518-48ee-9baa-0e42f5a2088f",
   "metadata": {},
   "source": [
    "<a id='sqlite'></a>\n",
    "## 3. Getting Started with SQLite "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b316844-fb7e-458a-84ea-31be758e93f8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## What is SQLite?\n",
    "\n",
    "SQLite is a lightweight relational database. It is easy to install, use, and even though it doesn't have as many advanced capabilities as PostgreSQL or MySQL, it is a great way to start learning SQL. SQL queries are very similar (if not identical) across these programs, so there is a lot of transfer of knowledge if you decide to move on to another one in the future.\n",
    "\n",
    "### SQLite vs. MySQL/PostgreSQL\n",
    "\n",
    "| Feature | SQLite | MySQL/PostgreSQL |\n",
    "|---------|--------|------------------|\n",
    "| Deployment | Single file | Server installation |\n",
    "| Configuration | None required | Requires setup |\n",
    "| Concurrency | Limited | High |\n",
    "| Size | Best for <1TB | Virtually unlimited |\n",
    "| Use cases | Local applications, prototyping, testing | Enterprise applications, web services |\n",
    "\n",
    "Examples: SQLite is used to store messages locally on WhatsApp, it is built into the Android OS for local storage of Apps.\n",
    "          Netflix, Spotify and Instagram use PostgreSQL\n",
    "\n",
    "üìù **Poll:** What's your primary reason for learning SQL today? \n",
    "\n",
    "TOM: This part below would be modified in the future, upload all the database examples I used in the main text.\n",
    "\n",
    "## Installing SQLite\n",
    "\n",
    "In this workshop, we'll work with SQLite directly in a Jupyter notebook using the `sqlite3` Python library, which comes built into Python.\n",
    "\n",
    "We could create tables with `CREATE TABLE` statements, as well as add new data (INSERT), change existing data (UPDATE), and remove data (DELETE) directly on SQL, but in this workshop we will focus on querying data from a pre-existing database. \n",
    "\n",
    "For now, let‚Äôs *import* a CSVs (`customers.csv`) so we have data to query.\n",
    "\n",
    "`pandas.DataFrame.to_sql()` conveniently:\n",
    "\n",
    "1. **Creates** a table matching the DataFrame‚Äôs columns  \n",
    "2. **Inserts** all rows in bulk (not optimal for millions of rows, but fine for demos)\n",
    "---\n",
    "> In this workshop we will be focusing on databases that contain a single table. In the next workshop, we will learn how to combine information from multiple tables. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f989e311",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58c5e594-41fd-40f2-be92-daec4d9ea400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First let's import the packages we will be needing:\n",
    "\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd         \n",
    "import os, pathlib, sys\n",
    "\n",
    "# The first thing we need to do is connect to our SQLite database, which is the file that stores the information we will be using.\n",
    "# If there is no pre-existing database with this name, it automatically creates one.\n",
    "# Every SQL query will be executed through this `conn` object - which can be thought as a channel to the SQLite file.\n",
    "conn = sqlite3.connect(\"first_workshop.sqlite\")\n",
    "\n",
    "# Load the CSV into a DataFrame and then into SQLite\n",
    "df = pd.read_csv(\"customers.csv\") # Reads the information from the CSV as a Pandas DataFrame\n",
    "df.to_sql(\"customers\", conn, if_exists=\"replace\", index=False) # Turns that Pandas DataFrame into a SQL table - overrides if needed.\n",
    "\n",
    "# By default, df.to_sql also returns the number of rows inserted into the SQL table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f897e82d",
   "metadata": {},
   "source": [
    "<a id='types'></a>\n",
    "## 4‚ÄØ¬∑‚ÄØSQLite Data Types & `NULL` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f538c404",
   "metadata": {},
   "source": [
    "SQLite has a flexible approach to data types. While columns are designed with a recommended data type (like TEXT or INTEGER), SQLite can actually store any type of data in any column.\n",
    "\n",
    "* **INTEGER** ‚Äì whole numbers \n",
    "* **REAL** ‚Äì floating‚Äëpoint  \n",
    "* **TEXT** ‚Äì strings    \n",
    "* **NULL** ‚Äì missing / undefined  \n",
    "\n",
    "Unlike PostgreSQL/MySQL, SQLite does NOT have a date format, but it does have dedicated functions that interpret strings as dates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6fe208",
   "metadata": {},
   "source": [
    "<a id='select'></a>\n",
    "## 5‚ÄØ¬∑‚ÄØSELECT & Derived Columns \n",
    "\n",
    "Real-World Application: Extract the relevant customer information for a marketing campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b1d2c2-434b-4bd5-be25-ae31e59278e4",
   "metadata": {},
   "source": [
    "At its most basic version, a query looks like this:\n",
    "\n",
    "```sql\n",
    "SELECT column1, column2, ‚Ä¶\n",
    "FROM   table;\n",
    "```\n",
    "\n",
    "- One of the most confusing aspects of SQL, especially in the beginning, is understading the order in which SQL reads the instructions of a query - which unfortunately is not the order in which the commands are written.\n",
    "- Here it is better to think that the first command is \"FROM\" - which tells us where to draw the information from\n",
    "- After that, we can select only the columns we will need by listing them after the SELECT statement.\n",
    "- Notice that:\n",
    "    - We don't need to put names of columns and tables between quotes\n",
    "    - We do need to separate different columns by commas - but not one at the end!\n",
    "\n",
    "üí° **Tip**: When selecting multiple columns, use line breaks after commas for better readability!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cb48082-f50e-4e31-b15d-beef77b47e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers Table:\n",
      "               name         city country  purchase_amount  purchase_price\n",
      "0        John Smith     New York      US                3          150.50\n",
      "1      Maria Garcia       Madrid      ES                1           49.99\n",
      "2      Ahmed Hassan        Cairo      EG                2           75.25\n",
      "3            Li Wei      Beijing      CN                5          250.00\n",
      "4        Emma Brown       London      GB                2           98.50\n",
      "5  Carlos Rodriguez  Mexico City      MX                1           39.99\n",
      "6     Sophie Martin        Paris      FR                4          199.75\n",
      "7      James Wilson       Sydney      AU                2           89.50\n",
      "8       Olga Petrov       Moscow      RU                3          120.25\n",
      "9         Raj Patel       Mumbai      IN                2           79.99\n",
      "\n",
      "Basic SELECT Example:\n",
      "               name country  purchase_price\n",
      "0        John Smith      US          150.50\n",
      "1      Maria Garcia      ES           49.99\n",
      "2      Ahmed Hassan      EG           75.25\n",
      "3            Li Wei      CN          250.00\n",
      "4        Emma Brown      GB           98.50\n",
      "5  Carlos Rodriguez      MX           39.99\n",
      "6     Sophie Martin      FR          199.75\n",
      "7      James Wilson      AU           89.50\n",
      "8       Olga Petrov      RU          120.25\n",
      "9         Raj Patel      IN           79.99\n"
     ]
    }
   ],
   "source": [
    "# Create a simple customers table\n",
    "customers_data = {\n",
    "    'name': ['John Smith', 'Maria Garcia', 'Ahmed Hassan', 'Li Wei', 'Emma Brown', \n",
    "             'Carlos Rodriguez', 'Sophie Martin', 'James Wilson', 'Olga Petrov', 'Raj Patel'],\n",
    "    'city': ['New York', 'Madrid', 'Cairo', 'Beijing', 'London', \n",
    "             'Mexico City', 'Paris', 'Sydney', 'Moscow', 'Mumbai'],\n",
    "    'country': ['US', 'ES', 'EG', 'CN', 'GB', \n",
    "                'MX', 'FR', 'AU', 'RU', 'IN'],\n",
    "    'purchase_amount': [3, 1, 2, 5, 2, \n",
    "                       1, 4, 2, 3, 2],\n",
    "    'purchase_price': [150.50, 49.99, 75.25, 250.00, 98.50, \n",
    "                      39.99, 199.75, 89.50, 120.25, 79.99]\n",
    "}\n",
    "customers_df = pd.DataFrame(customers_data)\n",
    "\n",
    "# Create in-memory database\n",
    "engine = create_engine('sqlite:///:memory:')\n",
    "customers_df.to_sql('customers', engine, index=False)\n",
    "\n",
    "print(\"Customers Table:\")\n",
    "print(customers_df)\n",
    "\n",
    "# Basic SELECT example\n",
    "basic_select_query = \"\"\"\n",
    "SELECT name, country, purchase_price\n",
    "FROM customers\n",
    "\"\"\"\n",
    "print(\"\\nBasic SELECT Example:\")\n",
    "print(pd.read_sql_query(basic_select_query, engine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813a20c8-208c-442b-a578-af51f14d7cd4",
   "metadata": {},
   "source": [
    "However, queries are extremely flexible and allow us to combine/summarize information in many ways.\n",
    "\n",
    "Let's take a look at some examples of more interesting queries\n",
    "\n",
    "### Step‚Äëby‚ÄëStep Examples\n",
    "\n",
    "1. **Select everything:**\n",
    "\n",
    "\n",
    "   If you want to keep all columns from a table, you can just use * instead of naming the columns.\n",
    "\n",
    "\n",
    "   ```sql\n",
    "   SELECT * \n",
    "   FROM customers;\n",
    "   ```\n",
    "   <br>\n",
    "\n",
    "2. **Select specific columns with aliases:**\n",
    "\n",
    "    Sometimes tables have very complicated/uninformative/ambiguous names. We can rename the header of a column using an alias:\n",
    "\n",
    "\n",
    "   ```sql\n",
    "   SELECT company_name AS name,\n",
    "          country\n",
    "   FROM   customers;\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dbe6098-6e2e-4c6d-a184-eae3d3beaf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers Table:\n",
      "               name         city country  purchase_amount  purchase_price\n",
      "0        John Smith     New York      US                3          150.50\n",
      "1      Maria Garcia       Madrid      ES                1           49.99\n",
      "2      Ahmed Hassan        Cairo      EG                2           75.25\n",
      "3            Li Wei      Beijing      CN                5          250.00\n",
      "4        Emma Brown       London      GB                2           98.50\n",
      "5  Carlos Rodriguez  Mexico City      MX                1           39.99\n",
      "6     Sophie Martin        Paris      FR                4          199.75\n",
      "7      James Wilson       Sydney      AU                2           89.50\n",
      "8       Olga Petrov       Moscow      RU                3          120.25\n",
      "9         Raj Patel       Mumbai      IN                2           79.99\n",
      "\n",
      "SELECT Example with select ALL:\n",
      "               name         city country  purchase_amount  purchase_price\n",
      "0        John Smith     New York      US                3          150.50\n",
      "1      Maria Garcia       Madrid      ES                1           49.99\n",
      "2      Ahmed Hassan        Cairo      EG                2           75.25\n",
      "3            Li Wei      Beijing      CN                5          250.00\n",
      "4        Emma Brown       London      GB                2           98.50\n",
      "5  Carlos Rodriguez  Mexico City      MX                1           39.99\n",
      "6     Sophie Martin        Paris      FR                4          199.75\n",
      "7      James Wilson       Sydney      AU                2           89.50\n",
      "8       Olga Petrov       Moscow      RU                3          120.25\n",
      "9         Raj Patel       Mumbai      IN                2           79.99\n",
      "\n",
      "SELECT Example with Alias:\n",
      "               name     location\n",
      "0        John Smith     New York\n",
      "1      Maria Garcia       Madrid\n",
      "2      Ahmed Hassan        Cairo\n",
      "3            Li Wei      Beijing\n",
      "4        Emma Brown       London\n",
      "5  Carlos Rodriguez  Mexico City\n",
      "6     Sophie Martin        Paris\n",
      "7      James Wilson       Sydney\n",
      "8       Olga Petrov       Moscow\n",
      "9         Raj Patel       Mumbai\n"
     ]
    }
   ],
   "source": [
    "# Original Table\n",
    "\n",
    "print(\"Customers Table:\")\n",
    "print(customers_df)\n",
    "\n",
    "# Selecting All columns\n",
    "select_all_query = \"\"\"\n",
    "SELECT *\n",
    "FROM customers\n",
    "\"\"\"\n",
    "print(\"\\nSELECT Example with select ALL:\")\n",
    "print(pd.read_sql_query(select_all_query, engine))\n",
    "\n",
    "# Using an Alias\n",
    "select_alias_query = \"\"\"\n",
    "SELECT name, city AS location \n",
    "FROM customers\n",
    "\"\"\"\n",
    "print(\"\\nSELECT Example with Alias:\")\n",
    "print(pd.read_sql_query(select_alias_query, engine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3408e250-286c-4d0c-8278-390f5815f3e2",
   "metadata": {},
   "source": [
    "Very commonly we might want to create what we call a \"Derived Column\" - which is a column that modifies/combines information from columns of the original table. \n",
    "\n",
    "The way that we do this is usually by using functions. The syntax is function(column_name). We treat them as if they were regular columns.\n",
    "\n",
    "6. **Derived columns:**  \n",
    "   ```sql\n",
    "   SELECT LOWER(name) AS lower_name,\n",
    "          UPPER(city) AS upper_city,\n",
    "          purchase_amount*2 AS double_amount\n",
    "   FROM   customers;\n",
    "   ```\n",
    "   <br>\n",
    "\n",
    "8. **Combining columns:**  \n",
    "   ```sql\n",
    "   SELECT name,\n",
    "          city || ', ' || country AS address,\n",
    "          purchase_amount * purchase_price AS expenditure\n",
    "   FROM   customers;\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea3c085d-8760-429e-b3d0-57645af0b094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers Table:\n",
      "               name         city country  purchase_amount  purchase_price\n",
      "0        John Smith     New York      US                3          150.50\n",
      "1      Maria Garcia       Madrid      ES                1           49.99\n",
      "2      Ahmed Hassan        Cairo      EG                2           75.25\n",
      "3            Li Wei      Beijing      CN                5          250.00\n",
      "4        Emma Brown       London      GB                2           98.50\n",
      "5  Carlos Rodriguez  Mexico City      MX                1           39.99\n",
      "6     Sophie Martin        Paris      FR                4          199.75\n",
      "7      James Wilson       Sydney      AU                2           89.50\n",
      "8       Olga Petrov       Moscow      RU                3          120.25\n",
      "9         Raj Patel       Mumbai      IN                2           79.99\n",
      "\n",
      "SELECT Example with Derived Columns:\n",
      "         lower_name   upper_city  double_amount\n",
      "0        john smith     NEW YORK              6\n",
      "1      maria garcia       MADRID              2\n",
      "2      ahmed hassan        CAIRO              4\n",
      "3            li wei      BEIJING             10\n",
      "4        emma brown       LONDON              4\n",
      "5  carlos rodriguez  MEXICO CITY              2\n",
      "6     sophie martin        PARIS              8\n",
      "7      james wilson       SYDNEY              4\n",
      "8       olga petrov       MOSCOW              6\n",
      "9         raj patel       MUMBAI              4\n",
      "\n",
      "SELECT Example with Combined Columns:\n",
      "               name          address  expenditure\n",
      "0        John Smith     New York, US       451.50\n",
      "1      Maria Garcia       Madrid, ES        49.99\n",
      "2      Ahmed Hassan        Cairo, EG       150.50\n",
      "3            Li Wei      Beijing, CN      1250.00\n",
      "4        Emma Brown       London, GB       197.00\n",
      "5  Carlos Rodriguez  Mexico City, MX        39.99\n",
      "6     Sophie Martin        Paris, FR       799.00\n",
      "7      James Wilson       Sydney, AU       179.00\n",
      "8       Olga Petrov       Moscow, RU       360.75\n",
      "9         Raj Patel       Mumbai, IN       159.98\n"
     ]
    }
   ],
   "source": [
    "# Original Table\n",
    "\n",
    "print(\"Customers Table:\")\n",
    "print(customers_df)\n",
    "\n",
    "# Selecting Derived columns\n",
    "select_derived_query = \"\"\"\n",
    "SELECT LOWER(name) AS lower_name,\n",
    "          UPPER(city) AS upper_city,\n",
    "          purchase_amount*2 AS double_amount\n",
    "   FROM   customers;\n",
    "\"\"\"\n",
    "print(\"\\nSELECT Example with Derived Columns:\")\n",
    "print(pd.read_sql_query(select_derived_query, engine))\n",
    "\n",
    "# Combining Columns\n",
    "select_combined_query = \"\"\"\n",
    "SELECT name,\n",
    "          city || ', ' || country AS address,\n",
    "          purchase_amount * purchase_price AS expenditure\n",
    "   FROM   customers;\n",
    "\"\"\"\n",
    "print(\"\\nSELECT Example with Combined Columns:\")\n",
    "print(pd.read_sql_query(select_combined_query, engine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb407d",
   "metadata": {},
   "source": [
    "We won't be able to cover all of them, but for future reference, here is a quick list of commonly used functions:\n",
    "\n",
    "### Commonly used Functions\n",
    "\n",
    "#### Text functions\n",
    "\n",
    "| Function | Description | Example |\n",
    "|----------|-------------|---------|\n",
    "| `SUBSTR(text, start, len)` | Substring (1‚Äëbased index) | `SUBSTR('Market',1,3)` ‚Üí `Mar` |\n",
    "| `INSTR(text, pattern)` | Position (0 if not found) | `INSTR('abcdef','cd')` ‚Üí `3` |\n",
    "| `LOWER(text)` / `UPPER(text)` | Case conversion | `LOWER('SQL')` ‚Üí `sql` |\n",
    "| `REPLACE(text, old, new)` | Global substitution | `REPLACE('foo','o','0')` |\n",
    "| `TRIM(text)` | Strip leading/trailing spaces | |\n",
    "| `str1 \\|\\| ' merging character ' \\|\\| str2 \\|\\|` | Concatenates strings\n",
    "\n",
    "#### Date / time Functions\n",
    "\n",
    "| Function | What it does | Example |\n",
    "|----------|--------------|---------|\n",
    "| `DATE('now')` | Current date (UTC) | `DATE('now')` ‚Üí `'2025‚Äë05‚Äë07'` |\n",
    "| `DATETIME('now','localtime')` | Current local datetime | `DATETIME('now','localtime')` ‚Üí `'2025‚Äë05‚Äë07¬†13:25:00'` |\n",
    "| `STRFTIME(fmt, ts)` | Format timestamp ‚Üí text | `STRFTIME('%Y‚Äë%m', OrderDate)` ‚Üí `'1997‚Äë07'` |\n",
    "| `JULIANDAY(ts)` | Days since noon¬†4714‚ÄØBC | `JULIANDAY('2025‚Äë05‚Äë07')` ‚Üí `2460457.5` |\n",
    "\n",
    "\n",
    "#### Integer and Float Functions\n",
    "\n",
    "| Expression | Result |\n",
    "|------------|--------|\n",
    "| `column1 + column2` | Add two numbers |\n",
    "| `ROUND(total * 0.15, 2)` | Round to 2‚ÄØdecimal places |\n",
    "| `COALESCE(price, 0)` | Replace NULL with 0 |\n",
    "\n",
    "üí°**Tip:** Need a float? Multiply an `INTEGER` by **`1.0`**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb64b41-c38d-4975-abb5-02a377e22a03",
   "metadata": {},
   "source": [
    "Now that we know the basics of querying, we can start dealing with more complex query commands - such as filtering, grouping, aggregate functions, sorting and paginating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f442956",
   "metadata": {},
   "source": [
    "<a id='where'></a>\n",
    "## 6‚ÄØ¬∑‚ÄØFiltering Rows with `WHERE` \n",
    "\n",
    "Real World Application: Find all large transactions on a list of business expenses for auditing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8569fc",
   "metadata": {},
   "source": [
    "Filtering is the process of selecting a subset of rows that match a certain condition. \n",
    "\n",
    "Filtering happens before selecting. This is at the crux of our desk-bookshelf analogy - we just want to query the data that we will be needing, so that it is manageable when it gets to our desk.\n",
    "\n",
    "The basic filtering method is WHERE, and the syntax is as follows:\n",
    "\n",
    "```sql\n",
    "SELECT columns\n",
    "FROM table\n",
    "WHERE condition\n",
    "\n",
    "```\n",
    "\n",
    "As we will see in a bit, the conditions we can impose are very flexible. But, as a first example, let's filter our previous database to those consumers who purchased more than one item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0301cf2-8ceb-478a-b6a5-827771ffe791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers Table:\n",
      "               name         city country  purchase_amount  purchase_price\n",
      "0        John Smith     New York      US                3          150.50\n",
      "1      Maria Garcia       Madrid      ES                1           49.99\n",
      "2      Ahmed Hassan        Cairo      EG                2           75.25\n",
      "3            Li Wei      Beijing      CN                5          250.00\n",
      "4        Emma Brown       London      GB                2           98.50\n",
      "5  Carlos Rodriguez  Mexico City      MX                1           39.99\n",
      "6     Sophie Martin        Paris      FR                4          199.75\n",
      "7      James Wilson       Sydney      AU                2           89.50\n",
      "8       Olga Petrov       Moscow      RU                3          120.25\n",
      "9         Raj Patel       Mumbai      IN                2           79.99\n",
      "\n",
      "SELECT Example with Filtered Rows:\n",
      "            name\n",
      "0     John Smith\n",
      "1   Ahmed Hassan\n",
      "2         Li Wei\n",
      "3     Emma Brown\n",
      "4  Sophie Martin\n",
      "5   James Wilson\n",
      "6    Olga Petrov\n",
      "7      Raj Patel\n"
     ]
    }
   ],
   "source": [
    "print(\"Customers Table:\")\n",
    "print(customers_df)\n",
    "\n",
    "# Selecting Filtered columns\n",
    "select_filtered_query = \"\"\"\n",
    "SELECT name\n",
    "FROM customers\n",
    "WHERE purchase_amount > 1\n",
    "\"\"\"\n",
    "print(\"\\nSELECT Example with Filtered Rows:\")\n",
    "print(pd.read_sql_query(select_filtered_query, engine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138a89b7-c0a0-4acd-8e6a-f2cd700e18f2",
   "metadata": {},
   "source": [
    "This example actually shows something very interesting about the WHERE statement - we don't need to keep the column we are using to filter the rows.\n",
    "\n",
    "In other words, let's say that we don't care too much about how much an user actually purchase, but we only want those who spend above a threshold. We can use WHERE combined with SELECT to use the information for filtering, but not keep it with us after it has been used, saving a lot of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214e958a-1bf2-488b-b6b7-2393ab2e9d26",
   "metadata": {},
   "source": [
    "Here are some commonly used filtering methods:\n",
    "\n",
    "1. **Equality / inequality**  \n",
    "   ```sql\n",
    "   ‚Ä¶ WHERE country = 'Germany';\n",
    "   ```\n",
    "‚ö†Ô∏è **Warning:** Be careful with string comparisons - they might be case-sensitive depending on the SQL engine and version you are using.\n",
    "\n",
    "2. **Set membership**  \n",
    "   ```sql\n",
    "   ‚Ä¶ WHERE country IN ('USA','UK','Germany');\n",
    "   ```\n",
    "\n",
    "> *Coming soon:* With **subqueries** we‚Äôll use `IN (SELECT ‚Ä¶)` to test *set membership* against *tables*, not just literal lists.\n",
    "\n",
    "üí° **Tip:** You can combine multiple logical expressions using AND/OR/NOT. When doing so, use parentheses to clarify when one logical expressions begins and the other ends.\n",
    "\n",
    "3. **Comparison**  \n",
    "   ```sql\n",
    "   ‚Ä¶ WHERE freight > 100;\n",
    "   ```\n",
    "\n",
    "üìù Poll: Which comparison operator would you use to find values in a specific range?\n",
    "\n",
    "4. **NULL checks**  \n",
    "   ```sql\n",
    "   ‚Ä¶ WHERE fax IS NULL;\n",
    "   ```\n",
    "\n",
    "‚ö†Ô∏è **Warning:** When you compare anything to NULL, the result isn't TRUE or FALSE, it is a special third type called UNKNOWN. \n",
    "\n",
    "This feature can be quite confusing, especially in the beginning. A common mistake is to try to find rows with missing values by using \n",
    "\n",
    "'WHERE column = NULL'\n",
    "\n",
    "This leads to the comparison  `NULL` **‚â†** `NULL` , which yields *UNKNOWN*, rather than TRUE.\n",
    "\n",
    "In SQL, we should instead use dedicated functions:\n",
    "\n",
    "```sql\n",
    "‚Ä¶ WHERE fax IS NULL\n",
    "‚Ä¶ WHERE fax IS NOT NULL\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f289c904-1011-4d6d-9db5-f534f62bd036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employees Table:\n",
      "   employee_id           name   department  manager_id\n",
      "0          101     John Smith  Engineering       201.0\n",
      "1          102  Sarah Johnson    Marketing       202.0\n",
      "2          103    Michael Lee      Finance         NaN\n",
      "3          104     Emma Davis         None       204.0\n",
      "4          105   David Wilson           HR       205.0\n",
      "\n",
      " Results using \"department = NULL\":\n",
      "Empty DataFrame\n",
      "Columns: [name, department]\n",
      "Index: []\n",
      "\n",
      " Results using \"department IS NULL\":\n",
      "None\n",
      "         name department\n",
      "0  Emma Davis       None\n"
     ]
    }
   ],
   "source": [
    "# Create a sample dataframe with NULL values\n",
    "employee_data = {\n",
    "    'employee_id': [101, 102, 103, 104, 105],\n",
    "    'name': ['John Smith', 'Sarah Johnson', 'Michael Lee', 'Emma Davis', 'David Wilson'],\n",
    "    'department': ['Engineering', 'Marketing', 'Finance', None, 'HR'],\n",
    "    'manager_id': [201, 202, None, 204, 205]\n",
    "}\n",
    "employees_df = pd.DataFrame(employee_data)\n",
    "\n",
    "# Create database\n",
    "engine = create_engine('sqlite:///:memory:')\n",
    "employees_df.to_sql('employees', engine, index=False)\n",
    "\n",
    "print(\"Employees Table:\")\n",
    "print(employees_df)\n",
    "\n",
    "incorrect_query = \"\"\"\n",
    "SELECT name, department\n",
    "FROM employees\n",
    "WHERE department = NULL\n",
    "\"\"\"\n",
    "print(\"\"\"\\n Results using \\\"department = NULL\\\":\"\"\")\n",
    "print(pd.read_sql_query(incorrect_query, engine))\n",
    "\n",
    "\n",
    "correct_query = \"\"\"\n",
    "SELECT name, department\n",
    "FROM employees\n",
    "WHERE department IS NULL\n",
    "\"\"\"\n",
    "print(print(\"\"\"\\n Results using \\\"department IS NULL\\\":\"\"\"))\n",
    "print(pd.read_sql_query(correct_query, engine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41b0249-803b-4f75-80ff-837571db36eb",
   "metadata": {},
   "source": [
    "<a id='groupby'></a>\n",
    "## 7‚ÄØ¬∑‚ÄØAggregate Functions & `GROUP BY` \n",
    "\n",
    "Real World Application: Given a list of individual transactions, calculate total sales per region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd18089-cd28-4048-b140-d4d8edf4b57f",
   "metadata": {},
   "source": [
    "Another way of pre-processing data so that the end result is more manageable is to summarize it according to a given statistic.\n",
    "\n",
    "One common example is the use of aggreggate functions, combined with GROUP BY, to collapse many rows into one, while keeping the information contained in them, only now summarized in a single row.\n",
    "\n",
    "First let's understand what the GROUP BY statement does: it creates subsets of the entire table that are similar in a given way. The most common way of doing so is to pass a column - and then SQL will automatically group the rows according to the values in that column\n",
    "\n",
    "Second, GROUP BY statements are used in conjunction with aggreggate functions. By grouping rows according to a given column, we can guarantee that the values of these rows match **for that particular column**. But what about the others? They might be different, in which case there is no obvious way of combining them. Aggregate functions do exactly this - they tell SQL what to do with mismatching information inside the group - for example by counting the number of occurrences, summing or taking averages:\n",
    "\n",
    "```sql\n",
    "SELECT country,\n",
    "       COUNT(*)        AS n_orders,\n",
    "       ROUND(AVG(freight),2) AS avg_freight\n",
    "FROM   orders\n",
    "GROUP  BY country\n",
    "```\n",
    "\n",
    "Another very important thing - which is a bit tough to get used to in the beginning, is that we can only include in the SELECT statement columns that are either used to group by observations, or ones that are used as inputs of aggregate functions. This is exactly because of what we discussed previously - if there is a mismatch between rows, SQL doesn't know how to handle these values when it collapses all the rows in the group into a single one.\n",
    "\n",
    "\n",
    "\n",
    "üí° **Tip**: Mathematical functions ignore `NULL` in aggregates (`AVG`, `SUM`), which is usually what you want. `COUNT(column)` counts only non‚Äënull values, whereas `COUNT(*)` counts *all* rows.\n",
    "\n",
    "A bit more advanced, but we can also pass more than one column to the GROUP BY statement - which would then create groups in which rows have the same values for all columns passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3bd53d24-3eac-469a-b62b-02ce1a4f2d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Customers Table:\n",
      "            name        city country  purchase_amount  purchase_price\n",
      "0     John Smith    New York      US                3          150.50\n",
      "1   Lisa Johnson     Chicago      US                2           89.99\n",
      "2   Maria Garcia      Madrid      ES                1           49.99\n",
      "3  Jose Martinez   Barcelona      ES                3          125.50\n",
      "4   Ahmed Hassan       Cairo      EG                2           75.25\n",
      "5     Fatima Ali  Alexandria      EG                1           60.00\n",
      "6         Li Wei     Beijing      CN                5          250.00\n",
      "7      Zhang Min    Shanghai      CN                3          175.25\n",
      "8     Emma Brown      London      GB                2           98.50\n",
      "9  William Jones  Manchester      GB                4          195.75\n",
      "\n",
      "Customers Grouped By Country:\n",
      "  country  customer_count  total_items  total_revenue  avg_purchase\n",
      "0      CN               2            8         425.25        212.63\n",
      "1      EG               2            3         135.25         67.63\n",
      "2      ES               2            4         175.49         87.75\n",
      "3      GB               2            6         294.25        147.13\n",
      "4      US               2            5         240.49        120.25\n"
     ]
    }
   ],
   "source": [
    "# Create a customer table with multiple people from the same countries\n",
    "customers_data = {\n",
    "    'name': ['John Smith', 'Lisa Johnson', 'Maria Garcia', 'Jose Martinez', \n",
    "             'Ahmed Hassan', 'Fatima Ali', 'Li Wei', 'Zhang Min', \n",
    "             'Emma Brown', 'William Jones'],\n",
    "    'city': ['New York', 'Chicago', 'Madrid', 'Barcelona', \n",
    "             'Cairo', 'Alexandria', 'Beijing', 'Shanghai', \n",
    "             'London', 'Manchester'],\n",
    "    'country': ['US', 'US', 'ES', 'ES', \n",
    "                'EG', 'EG', 'CN', 'CN', \n",
    "                'GB', 'GB'],\n",
    "    'purchase_amount': [3, 2, 1, 3, \n",
    "                        2, 1, 5, 3, \n",
    "                        2, 4],\n",
    "    'purchase_price': [150.50, 89.99, 49.99, 125.50, \n",
    "                       75.25, 60.00, 250.00, 175.25, \n",
    "                       98.50, 195.75]\n",
    "}\n",
    "customers_df = pd.DataFrame(customers_data)\n",
    "\n",
    "# Create database\n",
    "engine = create_engine('sqlite:///:memory:')\n",
    "customers_df.to_sql('customers', engine, index=False)\n",
    "\n",
    "# Display original data\n",
    "print(\"Original Customers Table:\")\n",
    "print(customers_df)\n",
    "\n",
    "# GROUP BY country query\n",
    "group_by_country_query = \"\"\"\n",
    "SELECT \n",
    "    country,\n",
    "    COUNT(*) AS customer_count,\n",
    "    SUM(purchase_amount) AS total_items,\n",
    "    SUM(purchase_price) AS total_revenue,\n",
    "    ROUND(AVG(purchase_price), 2) AS avg_purchase\n",
    "FROM \n",
    "    customers\n",
    "GROUP BY \n",
    "    country\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "result = pd.read_sql_query(group_by_country_query, engine)\n",
    "print(\"\\nCustomers Grouped By Country:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf7be3e-f54d-4edf-aeee-50e8101b7ae0",
   "metadata": {},
   "source": [
    "For future reference, here is a list of the most commonly used aggregate functions:\n",
    "\n",
    "| Aggregate¬†Function                                   | What it returns (typical usage)                    |\n",
    "| ---------------------------------------------------- | -------------------------------------------------- |\n",
    "| `COUNT(*)`                                           | Total number of rows in the group/query            |\n",
    "| `SUM(col)`                                           | Arithmetic sum of a numeric column                 |\n",
    "| `AVG(col)`                                           | Mean (average) of numeric values                   |\n",
    "| `MAX(col)`                                           | Largest value (numeric *or* lexicographic)         |\n",
    "| `MIN(col)`                                           | Smallest value (numeric *or* lexicographic)        |\n",
    "| `STRING_AGG(col, ', ')` / `GROUP_CONCAT` / `LISTAGG` | Concatenates strings in the group with a delimiter |\n",
    "| `COUNT(DISTINCT col)`                                | Count of unique, non-NULL values                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f02a85",
   "metadata": {},
   "source": [
    "<a id='orderby'></a>\n",
    "## 8‚ÄØ¬∑‚ÄØSorting & Paginating Results \n",
    "\n",
    "Real World Application: Find the top 10 selling items on a given year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3222d1e",
   "metadata": {},
   "source": [
    "After we have processed our data, we might want to start preparing it for visualization. In SQL, this is done mostly through sorting - ordering the data according to one or more columns - or paginating - retrieving only a fixed number of observations\n",
    "\n",
    "`ORDER¬†BY` is evaluated *after* `SELECT`.  \n",
    "\n",
    "* Default sort is **ASC** (ascending).  \n",
    "* Use **DESC** for descending order.  \n",
    "* You can order by *multiple* columns ‚Äì the second acts as a tie‚Äëbreaker.\n",
    "\n",
    "```sql\n",
    "SELECT company_name, country, city\n",
    "FROM   customers\n",
    "ORDER  BY country ASC, company_name DESC;\n",
    "```\n",
    "\n",
    "### Pagination Pattern\n",
    "\n",
    "LIMIT is used to restrict how many observations we want to retrieve\n",
    "OFFSET will skill a certain number of rows before displaying the number of results delimited by LIMIT\n",
    "\n",
    "\n",
    "```sql\n",
    "SELECT company_name, country, city\n",
    "FROM   customers\n",
    "ORDER  BY country\n",
    "LIMIT  n\n",
    "OFFSET m;\n",
    "```\n",
    "\n",
    "`LIMIT` must appear *before* `OFFSET` in SQLite.\n",
    "\n",
    "Observation: It is very hard to predict what the ordering will be after applying filtering or other methods. So remember to always GROUP BY before using LIMIT/OFFSET!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a668312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Original Table:\n",
      "            name        city country  purchase_amount  purchase_price\n",
      "0     John Smith    New York      US                3          150.50\n",
      "1   Lisa Johnson     Chicago      US                2           89.99\n",
      "2   Maria Garcia      Madrid      ES                1           49.99\n",
      "3  Jose Martinez   Barcelona      ES                3          125.50\n",
      "4   Ahmed Hassan       Cairo      EG                2           75.25\n",
      "5     Fatima Ali  Alexandria      EG                1           60.00\n",
      "6         Li Wei     Beijing      CN                5          250.00\n",
      "7      Zhang Min    Shanghai      CN                3          175.25\n",
      "8     Emma Brown      London      GB                2           98.50\n",
      "9  William Jones  Manchester      GB                4          195.75\n",
      "\n",
      " Ordered Table:\n",
      "            name        city country  purchase_amount  purchase_price\n",
      "0   Ahmed Hassan       Cairo      EG                2           75.25\n",
      "1     Emma Brown      London      GB                2           98.50\n",
      "2     Fatima Ali  Alexandria      EG                1           60.00\n",
      "3     John Smith    New York      US                3          150.50\n",
      "4  Jose Martinez   Barcelona      ES                3          125.50\n",
      "5         Li Wei     Beijing      CN                5          250.00\n",
      "6   Lisa Johnson     Chicago      US                2           89.99\n",
      "7   Maria Garcia      Madrid      ES                1           49.99\n",
      "8  William Jones  Manchester      GB                4          195.75\n",
      "9      Zhang Min    Shanghai      CN                3          175.25\n",
      "\n",
      "Customers Grouped By Country:\n",
      "            name       city country  purchase_amount  purchase_price\n",
      "0     John Smith   New York      US                3           150.5\n",
      "1  Jose Martinez  Barcelona      ES                3           125.5\n",
      "2         Li Wei    Beijing      CN                5           250.0\n"
     ]
    }
   ],
   "source": [
    "# Original Query\n",
    "original_country_query = \"\"\"\n",
    "SELECT *\n",
    "FROM customers\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "result = pd.read_sql_query(original_country_query, engine)\n",
    "print(\"\\n Original Table:\")\n",
    "print(result)\n",
    "\n",
    "\n",
    "# Ordered Country Query\n",
    "ordered_country_query = \"\"\"\n",
    "SELECT *\n",
    "FROM customers\n",
    "ORDER BY name\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "result = pd.read_sql_query(ordered_country_query, engine)\n",
    "print(\"\\n Ordered Table:\")\n",
    "print(result)\n",
    "\n",
    "# LIMIT/OFFSET country query\n",
    "limit_offset_country_query = \"\"\"\n",
    "SELECT *\n",
    "FROM customers\n",
    "ORDER BY name\n",
    "LIMIT 3\n",
    "OFFSET 3\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "result = pd.read_sql_query(limit_offset_country_query, engine)\n",
    "print(\"\\nCustomers Grouped By Country:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36a6335",
   "metadata": {},
   "source": [
    "<a id='having'></a>\n",
    "## 9‚ÄØ¬∑‚ÄØFiltering Groups with `HAVING` \n",
    "\n",
    "Real World Application: Find all product categories experiencing high growth over the last year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2615c6",
   "metadata": {},
   "source": [
    "Remember that when we discussed filtering, we used the WHERE command, which was run before the GROUP BY.\n",
    "\n",
    "Sometimes, we want to filter rows given an aggregate statement. For example, we might want to choose only the customers whose average expenditure is larger than a certain amount.\n",
    "\n",
    "`HAVING` is evaluated **after** grouping ‚Äì it filters *groups*, whereas `WHERE` filters *rows*.\n",
    "\n",
    "Two Observations:\n",
    "- We cannot use aggregate functions on WHERE statements\n",
    "- We must use HAVING after the GROUP BY statement\n",
    "\n",
    "```sql\n",
    "SELECT country,\n",
    "       COUNT(*) AS n_orders\n",
    "FROM   orders\n",
    "GROUP  BY country\n",
    "HAVING n_orders > 20          -- aggregate in condition\n",
    "ORDER  BY n_orders DESC;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bf7ac820-68b8-4faf-976c-5d04fb003e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Purchases Data:\n",
      "   customer_id customer_name  purchase_amount\n",
      "0          101         Alice           120.50\n",
      "1          101         Alice            85.99\n",
      "2          101         Alice            34.20\n",
      "3          102           Bob           199.99\n",
      "4          102           Bob            45.50\n",
      "5          103       Charlie            55.75\n",
      "6          103       Charlie            62.30\n",
      "7          103       Charlie            89.99\n",
      "8          103       Charlie            75.25\n",
      "9          104         David           350.00\n",
      "...\n",
      "\n",
      "Customers with Average Purchase > $100:\n",
      "   customer_id customer_name  purchase_count  total_spent  average_purchase\n",
      "0          104         David               2       640.75            320.38\n",
      "1          102           Bob               2       245.49            122.75\n",
      "2          106         Frank               4       417.49            104.37\n"
     ]
    }
   ],
   "source": [
    "# Create purchases data with multiple purchases per customer\n",
    "purchases_data = {\n",
    "    'customer_id': [101, 101, 101, 102, 102, 103, 103, 103, 103, \n",
    "                    104, 104, 105, 105, 105, 106, 106, 106, 106],\n",
    "    'customer_name': ['Alice', 'Alice', 'Alice', 'Bob', 'Bob', 'Charlie', 'Charlie', 'Charlie', 'Charlie',\n",
    "                     'David', 'David', 'Emma', 'Emma', 'Emma', 'Frank', 'Frank', 'Frank', 'Frank'],\n",
    "    'purchase_amount': [120.50, 85.99, 34.20, 199.99, 45.50, 55.75, 62.30, 89.99, 75.25,\n",
    "                        350.00, 290.75, 24.99, 19.99, 34.50, 125.99, 85.50, 95.25, 110.75]\n",
    "}\n",
    "purchases_df = pd.DataFrame(purchases_data)\n",
    "\n",
    "# Create database\n",
    "engine = create_engine('sqlite:///:memory:')\n",
    "purchases_df.to_sql('purchases', engine, index=False)\n",
    "\n",
    "# Display some sample data\n",
    "print(\"Sample Purchases Data:\")\n",
    "print(purchases_df.head(10))\n",
    "print(\"...\")\n",
    "\n",
    "# Query using HAVING to filter customers with average purchase > 100\n",
    "having_query = \"\"\"\n",
    "SELECT \n",
    "    customer_id,\n",
    "    customer_name,\n",
    "    COUNT(*) AS purchase_count,\n",
    "    SUM(purchase_amount) AS total_spent,\n",
    "    ROUND(AVG(purchase_amount), 2) AS average_purchase\n",
    "FROM \n",
    "    purchases\n",
    "GROUP BY \n",
    "    customer_id, customer_name\n",
    "HAVING \n",
    "    AVG(purchase_amount) > 100\n",
    "ORDER BY \n",
    "    average_purchase DESC\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "result = pd.read_sql_query(having_query, engine)\n",
    "print(\"\\nCustomers with Average Purchase > $100:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2094a318-876c-4b39-b2e1-10c568067e98",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "### Putting it all together\n",
    "\n",
    "We learned quite a few different commands for queries. Let's see one example that includes all of them:\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "    Country,\n",
    "    COUNT(OrderID)                AS total_orders,\n",
    "    ROUND(AVG(Freight), 2)        AS avg_freight\n",
    "FROM    customers \n",
    "WHERE   Country IN ('USA','UK','Germany')\n",
    "GROUP BY Country\n",
    "HAVING   COUNT(OrderID) >= 10\n",
    "ORDER BY total_orders DESC\n",
    "LIMIT 5;\n",
    "```\n",
    "\n",
    "The diagram reiterates the **logical query order**, not the command order, helping you remember the order in which the operations are actually made.\n",
    "\n",
    "![SQL Execution Order](sql-execution-order.svg)\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1e8bb1-5c3c-40ae-9538-84a635a5febc",
   "metadata": {},
   "source": [
    "### A visualization of the order of query commands\n",
    "\n",
    "**FROM¬†`customers`** ‚Äì full table (7¬†rows).\n",
    "\n",
    "| CustID | Country | Orders |\n",
    "|-------|---------|--------|\n",
    "| C1 | USA | 5 |\n",
    "| C2 | USA | 7 |\n",
    "| C3 | UK  | 3 |\n",
    "| C4 | UK  | 7 |\n",
    "| C5 | FRA | 15 |\n",
    "| C6 | GER | 2 |\n",
    "| C7 | CAN | 6 |\n",
    "\n",
    "---\n",
    "\n",
    "**WHERE¬†`Country IN ('USA','UK','FRA','GER')`** ‚Äì drop the Canadian row.\n",
    "\n",
    "| CustID | Country | Orders |\n",
    "|-------|---------|--------|\n",
    "| C1 | USA | 5 |\n",
    "| C2 | USA | 7 |\n",
    "| C3 | UK  | 3 |\n",
    "| C4 | UK  | 7 |\n",
    "| C5 | FRA | 15 |\n",
    "| C6 | GER | 2 |\n",
    "\n",
    "---\n",
    "\n",
    "**GROUP¬†BY¬†`Country`** ‚Äì aggregate rows, summing `Orders`.\n",
    "\n",
    "| Country | TotalOrders |\n",
    "|---------|-------------|\n",
    "| USA | 12 |\n",
    "| UK  | 10 |\n",
    "| FRA | 15 |\n",
    "| GER | 2  |\n",
    "\n",
    "---\n",
    "\n",
    "**HAVING¬†`TotalOrders > 5`** ‚Äì keep only groups with healthy order volume; Germany drops out.\n",
    "\n",
    "| Country | TotalOrders |\n",
    "|---------|-------------|\n",
    "| FRA | 15 |\n",
    "| USA | 12 |\n",
    "| UK  | 10 |\n",
    "\n",
    "---\n",
    "\n",
    "**SELECT¬†`Country, TotalOrders`** ‚Äì project just the columns we care about (already those two).\n",
    "\n",
    "| Country | TotalOrders |\n",
    "|---------|-------------|\n",
    "| FRA | 15 |\n",
    "| USA | 12 |\n",
    "| UK  | 10 |\n",
    "\n",
    "---\n",
    "\n",
    "**ORDER¬†BY¬†`TotalOrders DESC`** ‚Äì rank countries by order volume.\n",
    "\n",
    "| Country | TotalOrders |\n",
    "|---------|-------------|\n",
    "| FRA | 15 |\n",
    "| USA | 12 |\n",
    "| UK  | 10 |\n",
    "\n",
    "---\n",
    "\n",
    "**LIMIT¬†2** ‚Äì return only the top two performers.\n",
    "\n",
    "| Country | TotalOrders |\n",
    "|---------|-------------|\n",
    "| FRA | 15 |\n",
    "| USA | 12 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f5fa8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "<a id='keypoints'></a>\n",
    "<div class=\"alert alert-success\">  \n",
    "    \n",
    "## 11‚ÄØ¬∑‚ÄØKey Points & Next Steps \n",
    "\n",
    "* Use SQL to select and pre-process only the data you really need, then use this smaller dataset for analysis with pandas\n",
    "* SQLite is a zero‚Äëinstall, single‚Äëfile engine that still speaks standard SQL.  \n",
    "* Remember the logical query order to avoid confusion (`WHERE` vs `HAVING`).  \n",
    "\n",
    "### What‚Äôs Next?  \n",
    "In the **Advanced SQL** workshop we will tackle:\n",
    "\n",
    "* Creating & altering tables  \n",
    "* `JOIN`s (INNER, LEFT, RIGHT, FULL) and set operations\n",
    "* `JOIN` as selection  \n",
    "* Subqueries & Common Table Expressions (`WITH`)  \n",
    "* Window functions (`ROW_NUMBER`, `LAG`, `LEAD`)  \n",
    "* UNION\n",
    "* Pivoting\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
